{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google-landmark-v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/earroyoh/Kaggle/blob/master/Google-Landmark-Recognition-Challenge-2019/google-landmark-v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RXZT2UsyIVe_",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.mkdir('/tmp/google-landmark')\n",
        "os.mkdir('/tmp/google-landmark/train')\n",
        "\n",
        "from shutil import copyfile,rmtree\n",
        "\n",
        "#rmtree('/tmp/google-landmark/test')\n",
        "os.mkdir('/tmp/google-landmark/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GrO42T6Etjy",
        "colab_type": "code",
        "outputId": "072124b0-c6ca-4771-9386-490f6b526f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "# Download training images\n",
        "# I just download a few ones to create the model and not oversize colab environment\n",
        "!wget --no-check-certificate \\\n",
        "     https://s3.amazonaws.com/google-landmark/train/images_000.tar \\\n",
        "    -O /tmp/google-landmark/train/images_000.tar\n",
        "!wget --no-check-certificate \\\n",
        "     https://s3.amazonaws.com/google-landmark/train/images_100.tar \\\n",
        "    -O /tmp/google-landmark/train/images_100.tar\n",
        "#!wget --no-check-certificate \\\n",
        "#     https://s3.amazonaws.com/google-landmark/train/images_200.tar \\\n",
        "#    -O /tmp/google-landmark/train/images_200.tar\n",
        "#!wget --no-check-certificate \\\n",
        "#     https://s3.amazonaws.com/google-landmark/train/images_300.tar \\\n",
        "#    -O /tmp/google-landmark/train/images_300.tar\n",
        "#!wget --no-check-certificate \\\n",
        "#     https://s3.amazonaws.com/google-landmark/train/images_400.tar \\\n",
        "#    -O /tmp/google-landmark/train/images_400.tar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-19 14:37:29--  https://s3.amazonaws.com/google-landmark/train/images_000.tar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.82.19\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.82.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1067018752 (1018M) [application/x-tar]\n",
            "Saving to: ‘/tmp/google-landmark/train/images_000.tar’\n",
            "\n",
            "/tmp/google-landmar 100%[===================>]   1018M  35.5MB/s    in 29s     \n",
            "\n",
            "2019-05-19 14:37:59 (34.8 MB/s) - ‘/tmp/google-landmark/train/images_000.tar’ saved [1067018752/1067018752]\n",
            "\n",
            "--2019-05-19 14:38:01--  https://s3.amazonaws.com/google-landmark/train/images_100.tar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.99.157\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.99.157|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1073758208 (1.0G) [application/x-tar]\n",
            "Saving to: ‘/tmp/google-landmark/train/images_100.tar’\n",
            "\n",
            "/tmp/google-landmar 100%[===================>]   1.00G  35.8MB/s    in 30s     \n",
            "\n",
            "2019-05-19 14:38:30 (34.7 MB/s) - ‘/tmp/google-landmark/train/images_100.tar’ saved [1073758208/1073758208]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mLij6qde6Ox",
        "colab_type": "code",
        "outputId": "91b05bfb-b69f-470a-ced4-3d5586aae1d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# Download a training file as validation file\n",
        "!wget --no-check-certificate \\\n",
        "     https://s3.amazonaws.com/google-landmark/train/images_400.tar \\\n",
        "    -O /tmp/google-landmark/test/images_400.tar "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-19 14:38:33--  https://s3.amazonaws.com/google-landmark/train/images_400.tar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.200.141\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.200.141|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1073154048 (1023M) [application/x-tar]\n",
            "Saving to: ‘/tmp/google-landmark/test/images_400.tar’\n",
            "\n",
            "/tmp/google-landmar 100%[===================>]   1023M  36.5MB/s    in 29s     \n",
            "\n",
            "2019-05-19 14:39:03 (34.9 MB/s) - ‘/tmp/google-landmark/test/images_400.tar’ saved [1073154048/1073154048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9brUxyTpYZHy",
        "colab_type": "text"
      },
      "source": [
        "The following python code will use the OS library to use Operating System libraries, giving you access to the file system, and the zipfile library allowing you to unzip the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMhhz6dPKgWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "889d9886-bee9-498a-999b-25e979da9ecc"
      },
      "source": [
        "# Download CSV datasets with images id's and landmarks id's\n",
        "#!wget --no-check-certificate \\\n",
        "#     https://www.kaggle.com/google/google-landmarks-dataset/downloads/google-landmarks-dataset.zip \\\n",
        "#    -O /tmp/google-landmark/google-landmarks-dataset.zip\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "     https://s3.amazonaws.com/google-landmark/metadata/train.csv \\\n",
        "    -O /tmp/google-landmark/train.csv\n",
        "#!wget --no-check-certificate \\\n",
        "#     https://s3.amazonaws.com/google-landmark/metadata/test.csv \\\n",
        "#    -O /tmp/google-landmark/test.csv\n",
        "\n",
        "  \n",
        "# Extract files\n",
        "#import zipfile\n",
        "\n",
        "#local_zip = '/tmp/google-landmark/google-landmarks-dataset.zip'\n",
        "#zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "#zip_ref.extractall('/tmp/google-landmark')\n",
        "#zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-19 14:47:56--  https://s3.amazonaws.com/google-landmark/metadata/train.csv\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.179.229\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.179.229|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 525832518 (501M) [text/csv]\n",
            "Saving to: ‘/tmp/google-landmark/train.csv’\n",
            "\n",
            "/tmp/google-landmar 100%[===================>] 501.47M  35.7MB/s    in 15s     \n",
            "\n",
            "2019-05-19 14:48:11 (33.7 MB/s) - ‘/tmp/google-landmark/train.csv’ saved [525832518/525832518]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PLy3pthUS0D2",
        "colab": {}
      },
      "source": [
        "# Extract images tar files\n",
        "\n",
        "# OS system calls\n",
        "#!tar -xvf '/tmp/google-landmark/train/images_000.tar' -C '/tmp/google-landmark/train'\n",
        "#!tar -tvf '/tmp/google-landmark/train/images_100.tar' -C '/tmp/google-landmark/train'\n",
        "#!tar -tvf '/tmp/google-landmark/train/images_200.tar' -C '/tmp/google-landmark/train'\n",
        "#!tar -tvf '/tmp/google-landmark/train/images_300.tar' -C '/tmp/google-landmark/train'\n",
        "#!tar -tvf '/tmp/google-landmark/train/images_400.tar' -C '/tmp/google-landmark/train'\n",
        "#!tar -xvf '/tmp/google-landmark/test/images_499.tar' -C '/tmp/google-landmark/test'\n",
        "\n",
        "\n",
        "import tarfile\n",
        "\n",
        "tar = tarfile.open(\"/tmp/google-landmark/train/images_000.tar\")\n",
        "tar.extractall('/tmp/google-landmark/train')\n",
        "tar.close()\n",
        "tar = tarfile.open(\"/tmp/google-landmark/train/images_100.tar\")\n",
        "tar.extractall('/tmp/google-landmark/train')\n",
        "tar.close()\n",
        "\n",
        "tar = tarfile.open(\"/tmp/google-landmark/test/images_400.tar\")\n",
        "tar.extractall('/tmp/google-landmark/test')\n",
        "tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o-qUPyfO7Qr8"
      },
      "source": [
        "The contents of the .zip are extracted to the base directory `/tmp/google-landmark`, which in turn each contain `train` and `test` subdirectories.\n",
        "\n",
        "In short: The training set is the data that is used to tell the neural network model that 'this is what a horse looks like', 'this is what a human looks like' etc. \n",
        "\n",
        "One thing to pay attention to in this sample: We do not explicitly label the images as horses or humans. If you remember with the handwriting example earlier, we had labelled 'this is a 1', 'this is a 7' etc.  Later you'll see something called an ImageGenerator being used -- and this is coded to read images from subdirectories, and automatically label them from the name of that subdirectory. So, for example, you will have a 'training' directory containing a 'horses' directory and a 'humans' one. ImageGenerator will label the images appropriately for you, reducing a coding step. \n",
        "\n",
        "Let's define each of these directories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NR_M9nWN-K8B",
        "colab": {}
      },
      "source": [
        "# Directory with our training pictures\n",
        "train_dir = os.path.join('/tmp/google-landmark/train')\n",
        "\n",
        "# Directory with our validation pictures\n",
        "validation_dir = os.path.join('/tmp/google-landmark/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xcTMKw3b-9g",
        "colab_type": "code",
        "outputId": "60c1d952-e7f3-4767-ceb3-d70934fa5a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create dataframes for ImageDataGenerators flow_from_dataframe\n",
        "\n",
        "train_df = pd.read_csv(r\"/tmp/google-landmark/train.csv\", dtype=str)\n",
        "validation_df = pd.read_csv(r\"/tmp/google-landmark/test.csv\", dtype=str)\n",
        "\n",
        "# Data cleaning, remove None url's\n",
        "train_df['id'] = train_df['id'].str.strip()\n",
        "train_df = train_df[train_df[\"url\"] != \"None\"]\n",
        "validation_df['id'] = validation_df['id'].str.strip()\n",
        "validation_df = validation_df[validation_df[\"url\"] != \"None\"]\n",
        "\n",
        "# Obtain number of classes to create model's sotfmax layer later\n",
        "landmarks = train_df.groupby(\"landmark_id\").count()\n",
        "max_classes = landmarks.count()[\"id\"]\n",
        "max_classes\n",
        "#landmarks[:10]"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "203094"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtatwrobqBUC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScSnwSpbV4hC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1907
        },
        "outputId": "b1e3ae66-7428-4db4-ace2-225e8a66f1d8"
      },
      "source": [
        "# Temporary restrict dataframe to loaded tar images\n",
        "pretrain_df = train_df\n",
        "temp_df = pd.DataFrame(columns=['id'], dtype=str)\n",
        "for i in os.listdir('/tmp/google-landmark/train/0/0/0'):\n",
        "  temp_df = temp_df.append({'id': i[:-4]}, ignore_index=True)\n",
        "\n",
        "train_df = pretrain_df.loc[pretrain_df['id'].isin(temp_df['id'])]\n",
        "\n",
        "temp_df=pd.DataFrame(columns=['id'], dtype=str)\n",
        "for i in os.listdir('/tmp/google-landmark/test/c/c/f'):\n",
        "  temp_df = temp_df.append({'id': i[:-4]}, ignore_index=True)\n",
        "\n",
        "validation_df = pretrain_df.loc[pretrain_df['id'].isin(temp_df['id'])]\n",
        "\n",
        "# Try to fix None of Index are in columns error\n",
        "train_df.reset_index(drop=True)\n",
        "validation_df.reset_index(drop=True)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>landmark_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ccf070a2da242d56</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>138982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ccf678541107c686</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>75843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ccf517ccac9efce7</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>169308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ccfa23e3df9d768c</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>34908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ccf7a3d4f9cc2dd3</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>163706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ccf769b7586fb59f</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>181087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ccf7ad5e6c121a31</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>89920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ccfcde2dcb9a8881</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>17157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ccf6591d6b04e06e</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>50801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ccfbd4a003471b73</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>34796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ccf43c10cbfecc56</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>56969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ccf13ec21246e4a4</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>40751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ccf47566a1497062</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>130287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ccff991b26723d07</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>150596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ccf09dee1b85b4b5</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>201728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ccfcbf5eac15272c</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>13894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>ccf183b8c28728bd</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>36377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ccf49975c20c7405</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>41250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ccf8f0e52fc6cf98</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>108381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>ccfe6ad4f7565fa2</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>198957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>ccf3387f21a879a8</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>88782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>ccf262805eb45813</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>115483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>ccf9fcd3075a70ae</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>24996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ccf625a89b799afa</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ccf2e8774664b559</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>172647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>ccf6ad7211e2c2c7</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>81565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>ccf8fc7f6e5fa735</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>41635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>ccf3d24b355d6533</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>133517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>ccfdda529ee7e131</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>64438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>ccff30ca7ac071ee</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>85910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>ccf1eed5aea82aa7</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>53486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>ccf1a8e523e96cfc</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>40088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>ccf562289640ec25</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>132940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>ccff3bd97a2d1a82</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>35285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>ccf71b2207f3aa37</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>181701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>ccf69117d59bf694</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>117021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>ccf119775caeefd8</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>40770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>ccffa0079a0f834a</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>120197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>ccf243ba72ecbafb</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>42321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>ccfc3a5147295f91</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>183668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>ccf7194feb5834ce</td>\n",
              "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
              "      <td>16761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1006</th>\n",
              "      <td>ccfe1ccda2764e8f</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>57177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>ccf516e099cca7de</td>\n",
              "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
              "      <td>161827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1008</th>\n",
              "      <td>ccf13ac0f611aec3</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>109018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009</th>\n",
              "      <td>ccf59d4e58f54491</td>\n",
              "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
              "      <td>142881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1010</th>\n",
              "      <td>ccfdb339e0f01836</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>155104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1011</th>\n",
              "      <td>ccf84dd1a0c8262c</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>175783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1012</th>\n",
              "      <td>ccf76fe333b929ba</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>136017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>ccf5e9fe6d4147b6</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>176528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>ccfb9e2a202cf2ee</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>187882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1015</th>\n",
              "      <td>ccf7cf9b3c13f23c</td>\n",
              "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
              "      <td>23293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>ccfb068370c1e9e5</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>174872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017</th>\n",
              "      <td>ccfc2bb7617a46de</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>68511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1018</th>\n",
              "      <td>ccf1222cba2a7e62</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>62894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1019</th>\n",
              "      <td>ccfa49f5c091734a</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>149554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020</th>\n",
              "      <td>ccf979634c497c8e</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>152789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>ccfa6cfd3d7a810b</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>141288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1022</th>\n",
              "      <td>ccfda13a27058be9</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>9175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>ccffba6f27c9abb2</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>124155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>ccff16cecfcb7e67</td>\n",
              "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
              "      <td>121263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1025 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id  ... landmark_id\n",
              "0     ccf070a2da242d56  ...      138982\n",
              "1     ccf678541107c686  ...       75843\n",
              "2     ccf517ccac9efce7  ...      169308\n",
              "3     ccfa23e3df9d768c  ...       34908\n",
              "4     ccf7a3d4f9cc2dd3  ...      163706\n",
              "5     ccf769b7586fb59f  ...      181087\n",
              "6     ccf7ad5e6c121a31  ...       89920\n",
              "7     ccfcde2dcb9a8881  ...       17157\n",
              "8     ccf6591d6b04e06e  ...       50801\n",
              "9     ccfbd4a003471b73  ...       34796\n",
              "10    ccf43c10cbfecc56  ...       56969\n",
              "11    ccf13ec21246e4a4  ...       40751\n",
              "12    ccf47566a1497062  ...      130287\n",
              "13    ccff991b26723d07  ...      150596\n",
              "14    ccf09dee1b85b4b5  ...      201728\n",
              "15    ccfcbf5eac15272c  ...       13894\n",
              "16    ccf183b8c28728bd  ...       36377\n",
              "17    ccf49975c20c7405  ...       41250\n",
              "18    ccf8f0e52fc6cf98  ...      108381\n",
              "19    ccfe6ad4f7565fa2  ...      198957\n",
              "20    ccf3387f21a879a8  ...       88782\n",
              "21    ccf262805eb45813  ...      115483\n",
              "22    ccf9fcd3075a70ae  ...       24996\n",
              "23    ccf625a89b799afa  ...      196229\n",
              "24    ccf2e8774664b559  ...      172647\n",
              "25    ccf6ad7211e2c2c7  ...       81565\n",
              "26    ccf8fc7f6e5fa735  ...       41635\n",
              "27    ccf3d24b355d6533  ...      133517\n",
              "28    ccfdda529ee7e131  ...       64438\n",
              "29    ccff30ca7ac071ee  ...       85910\n",
              "...                ...  ...         ...\n",
              "995   ccf1eed5aea82aa7  ...       53486\n",
              "996   ccf1a8e523e96cfc  ...       40088\n",
              "997   ccf562289640ec25  ...      132940\n",
              "998   ccff3bd97a2d1a82  ...       35285\n",
              "999   ccf71b2207f3aa37  ...      181701\n",
              "1000  ccf69117d59bf694  ...      117021\n",
              "1001  ccf119775caeefd8  ...       40770\n",
              "1002  ccffa0079a0f834a  ...      120197\n",
              "1003  ccf243ba72ecbafb  ...       42321\n",
              "1004  ccfc3a5147295f91  ...      183668\n",
              "1005  ccf7194feb5834ce  ...       16761\n",
              "1006  ccfe1ccda2764e8f  ...       57177\n",
              "1007  ccf516e099cca7de  ...      161827\n",
              "1008  ccf13ac0f611aec3  ...      109018\n",
              "1009  ccf59d4e58f54491  ...      142881\n",
              "1010  ccfdb339e0f01836  ...      155104\n",
              "1011  ccf84dd1a0c8262c  ...      175783\n",
              "1012  ccf76fe333b929ba  ...      136017\n",
              "1013  ccf5e9fe6d4147b6  ...      176528\n",
              "1014  ccfb9e2a202cf2ee  ...      187882\n",
              "1015  ccf7cf9b3c13f23c  ...       23293\n",
              "1016  ccfb068370c1e9e5  ...      174872\n",
              "1017  ccfc2bb7617a46de  ...       68511\n",
              "1018  ccf1222cba2a7e62  ...       62894\n",
              "1019  ccfa49f5c091734a  ...      149554\n",
              "1020  ccf979634c497c8e  ...      152789\n",
              "1021  ccfa6cfd3d7a810b  ...      141288\n",
              "1022  ccfda13a27058be9  ...        9175\n",
              "1023  ccffba6f27c9abb2  ...      124155\n",
              "1024  ccff16cecfcb7e67  ...      121263\n",
              "\n",
              "[1025 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk3pE6xCdDcl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "outputId": "bff2149b-18d5-4a1b-b156-1d24017daa33"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>landmark_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [id, url, landmark_id]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5oqBkNBJmtUv"
      },
      "source": [
        "## Building a Small Model from Scratch\n",
        "\n",
        "But before we continue, let's start defining the model:\n",
        "\n",
        "Step 1 will be to import tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvfZg3LQbD-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "2b8e5f69-36f2-4f7c-de32-fda6b9fc1880"
      },
      "source": [
        "!pip install --pre -U tensorflow\n",
        "import tensorflow as tf"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (79.9MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9MB 14.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 39.5MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 35.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.3)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.4)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Collecting google-pasta>=0.1.2 (from tensorflow)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/68/a14620bfb042691f532dcde8576ff82ee82e4c003cdc0a3dbee5f289cee6/google_pasta-0.1.6-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 23.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (41.0.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow) (0.15.3)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow) (3.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, google-pasta, tensorflow\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed google-pasta-0.1.6 tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BnhYCP4tdqjC"
      },
      "source": [
        "We then add convolutional layers as in the previous example, and flatten the final result to feed into the densely connected layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gokG5HKpdtzm",
        "colab_type": "text"
      },
      "source": [
        "Finally we add the densely connected layers. \n",
        "\n",
        "Note that because we are facing a two-class classification problem, i.e. a *binary classification problem*, we will end our network with a [*softmax* activation](https://wikipedia.org/wiki/Sigmoid_function), so that the output of our network will be a single scalar between 0 and 1, encoding the probability that the current image is class 1 (as opposed to class 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PixZ2s5QbYQ3",
        "colab_type": "code",
        "outputId": "7bb318f8-5f56-4c20-935a-d78fe170f46d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final softmax layer for classification\n",
        "x = layers.Dense  (max_classes, activation='softmax')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-19 14:52:18--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.133.128, 2a00:1450:400c:c0b::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.133.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep   4%[                    ]   4.01M  15.5MB/s               \r        /tmp/incept  49%[========>           ]  41.79M  91.1MB/s               \r       /tmp/incepti  77%[==============>     ]  64.62M  98.1MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M   114MB/s    in 0.7s    \n",
            "\n",
            "2019-05-19 14:52:19 (114 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s9EaFDP5srBa"
      },
      "source": [
        "The model.summary() method call prints a summary of the NN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7ZKj8392nbgP",
        "outputId": "4818b3c0-5841-44fe-c0ee-a0e62100165b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9054
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 203094)       208171350   dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 255,682,806\n",
            "Trainable params: 246,707,542\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DmtkTn06pKxF"
      },
      "source": [
        "The \"output shape\" column shows how the size of your feature map evolves in each successive layer. The convolution layers reduce the size of the feature maps by a bit due to padding, and each pooling layer halves the dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PEkKSpZlvJXA"
      },
      "source": [
        "Next, we'll configure the specifications for model training. We will train our model with the `binary_crossentropy` loss, because it's a binary classification problem and our final activation is a sigmoid. (For a refresher on loss metrics, see the [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/descending-into-ml/video-lecture).) We will use the `rmsprop` optimizer with a learning rate of `0.001`. During training, we will want to monitor classification accuracy.\n",
        "\n",
        "**NOTE**: In this case, using the [RMSprop optimization algorithm](https://wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp) is preferable to [stochastic gradient descent](https://developers.google.com/machine-learning/glossary/#SGD) (SGD), because RMSprop automates learning-rate tuning for us. (Other optimizers, such as [Adam](https://wikipedia.org/wiki/Stochastic_gradient_descent#Adam) and [Adagrad](https://developers.google.com/machine-learning/glossary/#AdaGrad), also automatically adapt the learning rate during training, and would work equally well here.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8DHWhFP_uhq3",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sn9m9D3UimHM"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "Let's set up data generators that will read pictures in our source folders, convert them to `float32` tensors, and feed them (with their labels) to our network. We'll have one generator for the training images and one for the validation images. Our generators will yield batches of images of size 300x300 and their labels (binary).\n",
        "\n",
        "As you may already know, data that goes into neural networks should usually be normalized in some way to make it more amenable to processing by the network. (It is uncommon to feed raw pixels into a convnet.) In our case, we will preprocess our images by normalizing the pixel values to be in the `[0, 1]` range (originally all values are in the `[0, 255]` range).\n",
        "\n",
        "In Keras this can be done via the `keras.preprocessing.image.ImageDataGenerator` class using the `rescale` parameter. This `ImageDataGenerator` class allows you to instantiate generators of augmented image batches (and their labels) via `.flow(data, labels)` or `.flow_from_directory(directory)`. These generators can then be used with the Keras model methods that accept data generators as inputs: `fit_generator`, `evaluate_generator`, and `predict_generator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4Imls9zO3Qs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "fe8274b5-29e3-4ff0-af76-993a8d2db28a"
      },
      "source": [
        "#Add jpg extension to id column values\n",
        "def add_jpg(id):\n",
        "  return id + \".jpg\";\n",
        "\n",
        "train_df['id'] = train_df['id'].apply(add_jpg)\n",
        "validation_df['id'] = validation_df['id'].apply(add_jpg)\n",
        "train_df.head()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>landmark_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4209</th>\n",
              "      <td>000235ce813517a1.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>120911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11174</th>\n",
              "      <td>000b226dbc297197.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>197802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23686</th>\n",
              "      <td>000949bb3b6480cb.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>60384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24410</th>\n",
              "      <td>0009a3f520a07e16.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>181490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26635</th>\n",
              "      <td>000956cf141171cd.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>83553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         id  ... landmark_id\n",
              "4209   000235ce813517a1.jpg  ...      120911\n",
              "11174  000b226dbc297197.jpg  ...      197802\n",
              "23686  000949bb3b6480cb.jpg  ...       60384\n",
              "24410  0009a3f520a07e16.jpg  ...      181490\n",
              "26635  000956cf141171cd.jpg  ...       83553\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ClebU9NJg99G",
        "outputId": "20495dc9-337a-4a1f-fd4f-6819ff5050b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   zoom_range = 0.2) # Remove zoom_range augmentation when training the whole dataset                                 \n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        directory=os.path.join(train_dir, '/0/0/0/'), # This is the source directory for training images\n",
        "        x_col=\"id\",\n",
        "        y_col=\"landmark_id\",\n",
        "        shuffle=True,\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=128,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "        dataframe=validation_df,\n",
        "        directory=os.path.join(validation_dir, '/c/c/f/'),  # This is the source directory for training images\n",
        "        x_col=\"id\",\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=32,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 0 images belonging to 0 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'class'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-3058534c7154>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Since we use categorical_crossentropy loss, we need categorical labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         class_mode='categorical')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_dataframe\u001b[0;34m(self, dataframe, directory, x_col, y_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, drop_duplicates, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             \u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m         )\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, drop_duplicates)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# check that inputs match the required class_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py\u001b[0m in \u001b[0;36m_check_params\u001b[0;34m(self, df, x_col, y_col, classes)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'categorical'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 raise TypeError('If class_mode=\"{}\", y_col=\"{}\" column '\n\u001b[1;32m    189\u001b[0m                                 \u001b[0;34m'values must be type string, list or tuple.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'class'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K18ZEPU1mib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "5c1e48bc-8aeb-46d5-a7bb-f7704d234dbf"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>landmark_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4209</th>\n",
              "      <td>000235ce813517a1.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>120911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11174</th>\n",
              "      <td>000b226dbc297197.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>197802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23686</th>\n",
              "      <td>000949bb3b6480cb.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>60384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24410</th>\n",
              "      <td>0009a3f520a07e16.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>181490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26635</th>\n",
              "      <td>000956cf141171cd.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>83553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         id  ... landmark_id\n",
              "4209   000235ce813517a1.jpg  ...      120911\n",
              "11174  000b226dbc297197.jpg  ...      197802\n",
              "23686  000949bb3b6480cb.jpg  ...       60384\n",
              "24410  0009a3f520a07e16.jpg  ...      181490\n",
              "26635  000956cf141171cd.jpg  ...       83553\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mu3Jdwkjwax4"
      },
      "source": [
        "### Training\n",
        "Let's train for 15 epochs -- this may take a few minutes to run.\n",
        "\n",
        "Do note the values per epoch.\n",
        "\n",
        "The Loss and Accuracy are a great indication of progress of training. It's making a guess as to the classification of the training data, and then measuring it against the known label, calculating the result. Accuracy is the portion of correct guesses. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fb1_lgobv81m",
        "outputId": "a3630f00-261e-4881-d8ed-a7e175f43ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2221
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=8,  \n",
        "      epochs=15,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=8)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "8/8 [==============================] - 4s 545ms/step - loss: 0.1359 - acc: 0.9805\n",
            "9/9 [==============================] - 8s 922ms/step - loss: 1.0952e-07 - acc: 1.0000 - val_loss: 0.1359 - val_acc: 0.9805\n",
            "Epoch 2/40\n",
            "8/8 [==============================] - 4s 448ms/step - loss: 0.2913 - acc: 0.9766\n",
            "9/9 [==============================] - 8s 935ms/step - loss: 1.1077e-07 - acc: 1.0000 - val_loss: 0.2913 - val_acc: 0.9766\n",
            "Epoch 3/40\n",
            "8/8 [==============================] - 4s 450ms/step - loss: 0.2050 - acc: 0.9805\n",
            "9/9 [==============================] - 8s 931ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.2050 - val_acc: 0.9805\n",
            "Epoch 4/40\n",
            "8/8 [==============================] - 4s 453ms/step - loss: 0.1720 - acc: 0.9805\n",
            "9/9 [==============================] - 8s 935ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.1720 - val_acc: 0.9805\n",
            "Epoch 5/40\n",
            "8/8 [==============================] - 4s 451ms/step - loss: 0.1674 - acc: 0.9883\n",
            "9/9 [==============================] - 8s 926ms/step - loss: 1.0952e-07 - acc: 1.0000 - val_loss: 0.1674 - val_acc: 0.9883\n",
            "Epoch 6/40\n",
            "8/8 [==============================] - 4s 454ms/step - loss: 0.0964 - acc: 0.9805\n",
            "9/9 [==============================] - 8s 928ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.0964 - val_acc: 0.9805\n",
            "Epoch 7/40\n",
            "8/8 [==============================] - 4s 460ms/step - loss: 0.1081 - acc: 0.9805\n",
            "9/9 [==============================] - 8s 934ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9805\n",
            "Epoch 8/40\n",
            "8/8 [==============================] - 4s 451ms/step - loss: 0.2911 - acc: 0.9727\n",
            "9/9 [==============================] - 8s 934ms/step - loss: 1.0889e-07 - acc: 1.0000 - val_loss: 0.2911 - val_acc: 0.9727\n",
            "Epoch 9/40\n",
            "8/8 [==============================] - 4s 451ms/step - loss: 0.1366 - acc: 0.9805\n",
            "9/9 [==============================] - 8s 930ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.1366 - val_acc: 0.9805\n",
            "Epoch 10/40\n",
            "8/8 [==============================] - 4s 456ms/step - loss: 0.4217 - acc: 0.9609\n",
            "9/9 [==============================] - 8s 925ms/step - loss: 1.0952e-07 - acc: 1.0000 - val_loss: 0.4217 - val_acc: 0.9609\n",
            "Epoch 11/40\n",
            "8/8 [==============================] - 4s 452ms/step - loss: 0.1434 - acc: 0.9883\n",
            "9/9 [==============================] - 8s 941ms/step - loss: 1.0952e-07 - acc: 1.0000 - val_loss: 0.1434 - val_acc: 0.9883\n",
            "Epoch 12/40\n",
            "8/8 [==============================] - 4s 446ms/step - loss: 0.2939 - acc: 0.9609\n",
            "9/9 [==============================] - 8s 923ms/step - loss: 1.0952e-07 - acc: 1.0000 - val_loss: 0.2939 - val_acc: 0.9609\n",
            "Epoch 13/40\n",
            "8/8 [==============================] - 4s 439ms/step - loss: 0.1060 - acc: 0.9883\n",
            "9/9 [==============================] - 8s 942ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 0.9883\n",
            "Epoch 14/40\n",
            "8/8 [==============================] - 4s 450ms/step - loss: 0.3064 - acc: 0.9727\n",
            "9/9 [==============================] - 8s 917ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.3064 - val_acc: 0.9727\n",
            "Epoch 15/40\n",
            "8/8 [==============================] - 4s 449ms/step - loss: 0.1945 - acc: 0.9844\n",
            "9/9 [==============================] - 8s 928ms/step - loss: 1.1077e-07 - acc: 1.0000 - val_loss: 0.1945 - val_acc: 0.9844\n",
            "Epoch 16/40\n",
            "8/8 [==============================] - 4s 444ms/step - loss: 0.0035 - acc: 1.0000\n",
            "9/9 [==============================] - 8s 911ms/step - loss: 2.7664e-07 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
            "Epoch 17/40\n",
            "8/8 [==============================] - 4s 446ms/step - loss: 0.0630 - acc: 0.9961\n",
            "9/9 [==============================] - 8s 916ms/step - loss: 1.0952e-07 - acc: 1.0000 - val_loss: 0.0630 - val_acc: 0.9961\n",
            "Epoch 18/40\n",
            "8/8 [==============================] - 3s 435ms/step - loss: 0.0799 - acc: 0.9922\n",
            "9/9 [==============================] - 8s 913ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.0799 - val_acc: 0.9922\n",
            "Epoch 19/40\n",
            "8/8 [==============================] - 4s 452ms/step - loss: 0.1064 - acc: 0.9883\n",
            "9/9 [==============================] - 8s 926ms/step - loss: 1.0889e-07 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9883\n",
            "Epoch 20/40\n",
            "8/8 [==============================] - 4s 449ms/step - loss: 0.1156 - acc: 0.9922\n",
            "9/9 [==============================] - 8s 921ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9922\n",
            "Epoch 21/40\n",
            "8/8 [==============================] - 4s 450ms/step - loss: 0.0867 - acc: 0.9922\n",
            "9/9 [==============================] - 8s 938ms/step - loss: 1.0952e-07 - acc: 1.0000 - val_loss: 0.0867 - val_acc: 0.9922\n",
            "Epoch 22/40\n",
            "8/8 [==============================] - 4s 452ms/step - loss: 0.0982 - acc: 0.9922\n",
            "9/9 [==============================] - 8s 927ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9922\n",
            "Epoch 23/40\n",
            "8/8 [==============================] - 4s 447ms/step - loss: 0.0396 - acc: 0.9961\n",
            "9/9 [==============================] - 8s 928ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.0396 - val_acc: 0.9961\n",
            "Epoch 24/40\n",
            "8/8 [==============================] - 4s 451ms/step - loss: 0.0368 - acc: 0.9961\n",
            "9/9 [==============================] - 9s 952ms/step - loss: 1.0889e-07 - acc: 1.0000 - val_loss: 0.0368 - val_acc: 0.9961\n",
            "Epoch 25/40\n",
            "8/8 [==============================] - 4s 454ms/step - loss: 0.0756 - acc: 0.9883\n",
            "9/9 [==============================] - 8s 943ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.0756 - val_acc: 0.9883\n",
            "Epoch 26/40\n",
            "8/8 [==============================] - 4s 451ms/step - loss: 0.0550 - acc: 0.9922\n",
            "9/9 [==============================] - 9s 957ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.0550 - val_acc: 0.9922\n",
            "Epoch 27/40\n",
            "8/8 [==============================] - 4s 455ms/step - loss: 0.1498 - acc: 0.9844\n",
            "9/9 [==============================] - 8s 923ms/step - loss: 1.0962e-07 - acc: 1.0000 - val_loss: 0.1498 - val_acc: 0.9844\n",
            "Epoch 28/40\n",
            "8/8 [==============================] - 4s 452ms/step - loss: 0.1610 - acc: 0.9844\n",
            "9/9 [==============================] - 8s 928ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.1610 - val_acc: 0.9844\n",
            "Epoch 29/40\n",
            "8/8 [==============================] - 4s 441ms/step - loss: 0.0592 - acc: 0.9922\n",
            "9/9 [==============================] - 8s 932ms/step - loss: 1.0952e-07 - acc: 1.0000 - val_loss: 0.0592 - val_acc: 0.9922\n",
            "Epoch 30/40\n",
            "8/8 [==============================] - 4s 451ms/step - loss: 0.1239 - acc: 0.9883\n",
            "9/9 [==============================] - 9s 945ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9883\n",
            "Epoch 31/40\n",
            "8/8 [==============================] - 4s 457ms/step - loss: 0.0442 - acc: 0.9961\n",
            "9/9 [==============================] - 8s 938ms/step - loss: 1.0952e-07 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 0.9961\n",
            "Epoch 32/40\n",
            "8/8 [==============================] - 4s 457ms/step - loss: 0.0630 - acc: 0.9961\n",
            "9/9 [==============================] - 8s 943ms/step - loss: 1.1137e-07 - acc: 1.0000 - val_loss: 0.0630 - val_acc: 0.9961\n",
            "Epoch 33/40\n",
            "8/8 [==============================] - 4s 452ms/step - loss: 0.0741 - acc: 0.9922\n",
            "9/9 [==============================] - 8s 933ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.0741 - val_acc: 0.9922\n",
            "Epoch 34/40\n",
            "8/8 [==============================] - 4s 447ms/step - loss: 0.0640 - acc: 0.9961\n",
            "9/9 [==============================] - 8s 912ms/step - loss: 1.0952e-07 - acc: 1.0000 - val_loss: 0.0640 - val_acc: 0.9961\n",
            "Epoch 35/40\n",
            "8/8 [==============================] - 4s 449ms/step - loss: 0.0307 - acc: 0.9961\n",
            "9/9 [==============================] - 8s 916ms/step - loss: 1.1015e-07 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 0.9961\n",
            "Epoch 36/40\n",
            "8/8 [==============================] - 4s 446ms/step - loss: 0.0015 - acc: 1.0000\n",
            "9/9 [==============================] - 8s 929ms/step - loss: 1.0952e-07 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 37/40\n",
            "8/8 [==============================] - 4s 453ms/step - loss: 0.0918 - acc: 0.9883\n",
            "9/9 [==============================] - 9s 947ms/step - loss: 1.1077e-07 - acc: 1.0000 - val_loss: 0.0918 - val_acc: 0.9883\n",
            "Epoch 38/40\n",
            "8/8 [==============================] - 4s 455ms/step - loss: 0.0150 - acc: 0.9961\n",
            "9/9 [==============================] - 8s 931ms/step - loss: 1.0889e-07 - acc: 1.0000 - val_loss: 0.0150 - val_acc: 0.9961\n",
            "Epoch 39/40\n",
            "8/8 [==============================] - 4s 452ms/step - loss: 0.1508 - acc: 0.9883\n",
            "9/9 [==============================] - 9s 948ms/step - loss: 1.2692e-07 - acc: 1.0000 - val_loss: 0.1508 - val_acc: 0.9883\n",
            "Epoch 40/40\n",
            "8/8 [==============================] - 4s 452ms/step - loss: 0.1040 - acc: 0.9922\n",
            "9/9 [==============================] - 8s 935ms/step - loss: 1.0952e-07 - acc: 1.0000 - val_loss: 0.1040 - val_acc: 0.9922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WF5y2l4hknb",
        "colab_type": "text"
      },
      "source": [
        "### Plot accuracy\n",
        "\n",
        "Plot training and validation accuracy to check overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1dQ3LUvhViK",
        "colab_type": "code",
        "outputId": "8746b1ca-9a9f-4559-e640-802280521841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6vSHzPR2ghH",
        "colab_type": "text"
      },
      "source": [
        "###Running the Model\n",
        "\n",
        "Let's now take a look at actually running a prediction using the model. This code will allow you to choose 1 or more files from your file system, it will then upload them, and run them through the model, giving an indication of whether the object is a horse or a human."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoWp43WxJDNT",
        "colab_type": "code",
        "outputId": "c4565e7f-1ebe-45b3-db41-578f7aca0e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a human\")\n",
        "  else:\n",
        "    print(fn + \" is a horse\")\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7214dc18-ad44-414e-9b40-250dca511d32\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7214dc18-ad44-414e-9b40-250dca511d32\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-83f6644adb6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: google.colab._files is undefined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-8EHQyWGDvWz"
      },
      "source": [
        "### Visualizing Intermediate Representations\n",
        "\n",
        "To get a feel for what kind of features our convnet has learned, one fun thing to do is to visualize how an input gets transformed as it goes through the convnet.\n",
        "\n",
        "Let's pick a random image from the training set, and then generate a figure where each row is the output of a layer, and each image in the row is a specific filter in that output feature map. Rerun this cell to generate intermediate representations for a variety of training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-5tES8rXFjux",
        "outputId": "68f394bf-3918-44e1-a5a4-fb6bbc9676e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Let's define a new Model that will take an image as input, and will output\n",
        "# intermediate representations for all layers in the previous model after\n",
        "# the first.\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "#visualization_model = Model(img_input, successive_outputs)\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
        "# Let's prepare a random input image from the training set.\n",
        "train_horse_names = os.listdir(train_horse_dir)\n",
        "train_human_names = os.listdir(train_human_dir)\n",
        "horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n",
        "human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n",
        "img_path = random.choice(horse_img_files + human_img_files)\n",
        "\n",
        "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
        "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
        "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /= 255\n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "# Now let's display our representations\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  if len(feature_map.shape) == 4:\n",
        "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = feature_map.shape[1]\n",
        "    # We will tile our images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    for i in range(n_features):\n",
        "      # Postprocess the feature to make it visually palatable\n",
        "      x = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std()\n",
        "      x *= 64\n",
        "      x += 128\n",
        "      x = np.clip(x, 0, 255).astype('uint8')\n",
        "      # We'll tile each filter into this big horizontal grid\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "    # Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure(figsize=(scale * n_features, scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-410a39ea43f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvisualization_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuccessive_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Let's prepare a random input image from the training set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhorse_img_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_horse_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_horse_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mhuman_img_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_human_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_human_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhorse_img_files\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhuman_img_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_horse_names' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tuqK2arJL0wo"
      },
      "source": [
        "As you can see we go from the raw pixels of the images to increasingly abstract and compact representations. The representations downstream start highlighting what the network pays attention to, and they show fewer and fewer features being \"activated\"; most are set to zero. This is called \"sparsity.\" Representation sparsity is a key feature of deep learning.\n",
        "\n",
        "\n",
        "These representations carry increasingly less information about the original pixels of the image, but increasingly refined information about the class of the image. You can think of a convnet (or a deep network in general) as an information distillation pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j4IBgYCYooGD"
      },
      "source": [
        "## Clean Up\n",
        "\n",
        "Before running the next exercise, run the following cell to terminate the kernel and free memory resources:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "651IgjLyo-Jx",
        "colab": {}
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}