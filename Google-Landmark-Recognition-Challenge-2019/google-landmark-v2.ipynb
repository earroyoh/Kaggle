{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/earroyoh/Kaggle/blob/master/Google-Landmark-Recognition-Challenge-2019/google-landmark-v2-simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "RXZT2UsyIVe_",
    "outputId": "cf8f8803-2e2b-4434-d3c6-42afee6a35b6"
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/tmp/google-landmark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2d534cdeb9ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mshutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopyfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/google-landmark'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/google-landmark/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/tmp/google-landmark'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from shutil import copyfile,rmtree\n",
    "\n",
    "os.mkdir('/tmp/google-landmark')\n",
    "os.mkdir('/tmp/google-landmark/train')\n",
    "\n",
    "#rmtree('/tmp/google-landmark/test')\n",
    "os.mkdir('/tmp/google-landmark/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1637
    },
    "colab_type": "code",
    "id": "4GrO42T6Etjy",
    "outputId": "b816411c-2871-43b0-90c6-7308c44869b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-21 15:56:47--  https://s3.amazonaws.com/google-landmark/train/images_000.tar\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.186.117\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.186.117|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1067018752 (1018M) [application/x-tar]\n",
      "Saving to: ‘/tmp/google-landmark/train/images_000.tar’\n",
      "\n",
      "/tmp/google-landmar 100%[===================>]   1018M  39.3MB/s    in 28s     \n",
      "\n",
      "2019-05-21 15:57:15 (37.0 MB/s) - ‘/tmp/google-landmark/train/images_000.tar’ saved [1067018752/1067018752]\n",
      "\n",
      "--2019-05-21 15:57:15--  https://s3.amazonaws.com/google-landmark/train/images_050.tar\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.135.29\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.135.29|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1066296320 (1017M) [application/x-tar]\n",
      "Saving to: ‘/tmp/google-landmark/train/images_050.tar’\n",
      "\n",
      "/tmp/google-landmar 100%[===================>]   1017M  59.6MB/s    in 20s     \n",
      "\n",
      "2019-05-21 15:57:35 (51.7 MB/s) - ‘/tmp/google-landmark/train/images_050.tar’ saved [1066296320/1066296320]\n",
      "\n",
      "--2019-05-21 15:57:36--  https://s3.amazonaws.com/google-landmark/train/images_100.tar\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.179.149\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.179.149|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1073758208 (1.0G) [application/x-tar]\n",
      "Saving to: ‘/tmp/google-landmark/train/images_100.tar’\n",
      "\n",
      "/tmp/google-landmar 100%[===================>]   1.00G  58.3MB/s    in 18s     \n",
      "\n",
      "2019-05-21 15:57:54 (57.7 MB/s) - ‘/tmp/google-landmark/train/images_100.tar’ saved [1073758208/1073758208]\n",
      "\n",
      "--2019-05-21 15:57:55--  https://s3.amazonaws.com/google-landmark/train/images_150.tar\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.147.45\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.147.45|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1070785536 (1021M) [application/x-tar]\n",
      "Saving to: ‘/tmp/google-landmark/train/images_150.tar’\n",
      "\n",
      "/tmp/google-landmar 100%[===================>]   1021M  52.2MB/s    in 19s     \n",
      "\n",
      "2019-05-21 15:58:15 (52.9 MB/s) - ‘/tmp/google-landmark/train/images_150.tar’ saved [1070785536/1070785536]\n",
      "\n",
      "--2019-05-21 15:58:16--  https://s3.amazonaws.com/google-landmark/train/images_200.tar\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.145.237\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.145.237|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1073142784 (1023M) [application/x-tar]\n",
      "Saving to: ‘/tmp/google-landmark/train/images_200.tar’\n",
      "\n",
      "/tmp/google-landmar 100%[===================>]   1023M  59.9MB/s    in 18s     \n",
      "\n",
      "2019-05-21 15:58:35 (55.5 MB/s) - ‘/tmp/google-landmark/train/images_200.tar’ saved [1073142784/1073142784]\n",
      "\n",
      "--2019-05-21 15:58:35--  https://s3.amazonaws.com/google-landmark/train/images_250.tar\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.0.198\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.0.198|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1070467072 (1021M) [application/x-tar]\n",
      "Saving to: ‘/tmp/google-landmark/train/images_250.tar’\n",
      "\n",
      "/tmp/google-landmar 100%[===================>]   1021M  51.6MB/s    in 19s     \n",
      "\n",
      "2019-05-21 15:58:55 (53.5 MB/s) - ‘/tmp/google-landmark/train/images_250.tar’ saved [1070467072/1070467072]\n",
      "\n",
      "--2019-05-21 15:58:56--  https://s3.amazonaws.com/google-landmark/train/images_300.tar\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.137.254\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.137.254|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1072676864 (1023M) [application/x-tar]\n",
      "Saving to: ‘/tmp/google-landmark/train/images_300.tar’\n",
      "\n",
      "/tmp/google-landmar 100%[===================>]   1023M  52.0MB/s    in 20s     \n",
      "\n",
      "2019-05-21 15:59:16 (50.3 MB/s) - ‘/tmp/google-landmark/train/images_300.tar’ saved [1072676864/1072676864]\n",
      "\n",
      "--2019-05-21 15:59:18--  https://s3.amazonaws.com/google-landmark/train/images_350.tar\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.10.93\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.10.93|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1073489920 (1024M) [application/x-tar]\n",
      "Saving to: ‘/tmp/google-landmark/train/images_350.tar’\n",
      "\n",
      "/tmp/google-landmar 100%[===================>]   1024M  59.9MB/s    in 20s     \n",
      "\n",
      "2019-05-21 15:59:38 (50.9 MB/s) - ‘/tmp/google-landmark/train/images_350.tar’ saved [1073489920/1073489920]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training images\n",
    "# I just download a few ones to create the model and not oversize colab environment\n",
    "!wget --no-check-certificate \\\n",
    "     https://s3.amazonaws.com/google-landmark/train/images_000.tar \\\n",
    "    -O /tmp/google-landmark/train/images_000.tar\n",
    "!wget --no-check-certificate \\\n",
    "     https://s3.amazonaws.com/google-landmark/train/images_050.tar \\\n",
    "    -O /tmp/google-landmark/train/images_050.tar\n",
    "!wget --no-check-certificate \\\n",
    "     https://s3.amazonaws.com/google-landmark/train/images_100.tar \\\n",
    "    -O /tmp/google-landmark/train/images_100.tar\n",
    "!wget --no-check-certificate \\\n",
    "     https://s3.amazonaws.com/google-landmark/train/images_150.tar \\\n",
    "    -O /tmp/google-landmark/train/images_150.tar\n",
    "!wget --no-check-certificate \\\n",
    "     https://s3.amazonaws.com/google-landmark/train/images_200.tar \\\n",
    "    -O /tmp/google-landmark/train/images_200.tar\n",
    "!wget --no-check-certificate \\\n",
    "     https://s3.amazonaws.com/google-landmark/train/images_250.tar \\\n",
    "    -O /tmp/google-landmark/train/images_250.tar\n",
    "!wget --no-check-certificate \\\n",
    "     https://s3.amazonaws.com/google-landmark/train/images_300.tar \\\n",
    "    -O /tmp/google-landmark/train/images_300.tar\n",
    "!wget --no-check-certificate \\\n",
    "     https://s3.amazonaws.com/google-landmark/train/images_350.tar \\\n",
    "    -O /tmp/google-landmark/train/images_350.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "0mLij6qde6Ox",
    "outputId": "06bf7d22-0b55-47c8-bc29-56d68d3b46de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will not apply HSTS. The HSTS database must be a regular and non-world-writable file.\n",
      "ERROR: could not open HSTS store at '/home/enri/.wget-hsts'. HSTS will be disabled.\n",
      "--2019-05-22 09:16:31--  https://s3.amazonaws.com/google-landmark/train/images_000.tar\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.162.205\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.162.205|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1067018752 (1018M) [application/x-tar]\n",
      "Saving to: ‘/tmp/google-landmark/train/images_000.tar’\n",
      "\n",
      "/tmp/google-landmar 100%[===================>]   1018M  4.13MB/s    in 4m 3s   \n",
      "\n",
      "2019-05-22 09:20:35 (4.19 MB/s) - ‘/tmp/google-landmark/train/images_000.tar’ saved [1067018752/1067018752]\n",
      "\n",
      "Will not apply HSTS. The HSTS database must be a regular and non-world-writable file.\n",
      "ERROR: could not open HSTS store at '/home/enri/.wget-hsts'. HSTS will be disabled.\n",
      "--2019-05-22 09:20:35--  https://s3.amazonaws.com/google-landmark/train/images_400.tar\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.100.69\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.100.69|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1073154048 (1023M) [application/x-tar]\n",
      "Saving to: ‘/tmp/google-landmark/test/images_400.tar’\n",
      "\n",
      "/tmp/google-landmar 100%[===================>]   1023M  5.36MB/s    in 5m 5s   \n",
      "\n",
      "2019-05-22 09:25:41 (3.36 MB/s) - ‘/tmp/google-landmark/test/images_400.tar’ saved [1073154048/1073154048]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download a training file as validation file\n",
    "!wget --no-check-certificate \\\n",
    "     https://s3.amazonaws.com/google-landmark/train/images_000.tar \\\n",
    "    -O /tmp/google-landmark/train/images_000.tar\n",
    "!wget --no-check-certificate \\\n",
    "     https://s3.amazonaws.com/google-landmark/train/images_400.tar \\\n",
    "    -O /tmp/google-landmark/test/images_400.tar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9brUxyTpYZHy"
   },
   "source": [
    "The following python code will use the OS library to use Operating System libraries, giving you access to the file system, and the zipfile library allowing you to unzip the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "wMhhz6dPKgWC",
    "outputId": "ba096272-40a5-4470-a38c-ad4d9ebf3d40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-21 16:00:09--  https://s3.amazonaws.com/google-landmark/metadata/train.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.170.117\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.170.117|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 525832518 (501M) [text/csv]\n",
      "Saving to: ‘/tmp/google-landmark/train.csv’\n",
      "\n",
      "/tmp/google-landmar 100%[===================>] 501.47M  48.4MB/s    in 13s     \n",
      "\n",
      "2019-05-21 16:00:22 (39.4 MB/s) - ‘/tmp/google-landmark/train.csv’ saved [525832518/525832518]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download CSV datasets with images id's and landmarks id's\n",
    "#!wget --no-check-certificate \\\n",
    "#     https://www.kaggle.com/google/google-landmarks-dataset/downloads/google-landmarks-dataset.zip \\\n",
    "#    -O /tmp/google-landmark/google-landmarks-dataset.zip\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "     https://s3.amazonaws.com/google-landmark/metadata/train.csv \\\n",
    "    -O /tmp/google-landmark/train.csv\n",
    "#!wget --no-check-certificate \\\n",
    "#     https://s3.amazonaws.com/google-landmark/metadata/test.csv \\\n",
    "#    -O /tmp/google-landmark/test.csv\n",
    "\n",
    "  \n",
    "# Extract files\n",
    "#import zipfile\n",
    "\n",
    "#local_zip = '/tmp/google-landmark/google-landmarks-dataset.zip'\n",
    "#zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "#zip_ref.extractall('/tmp/google-landmark')\n",
    "#zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "tar = tarfile.open(\"/tmp/google-landmark/train/images_000.tar\")\n",
    "tar.extractall('/tmp/google-landmark/train')\n",
    "tar.close()\n",
    "tar = tarfile.open(\"/tmp/google-landmark/test/images_400.tar\")\n",
    "tar.extractall('/tmp/google-landmark/test')\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PLy3pthUS0D2"
   },
   "outputs": [],
   "source": [
    "# Extract images tar files\n",
    "\n",
    "# OS system calls\n",
    "#c\n",
    "#!tar -tvf '/tmp/google-landmark/train/images_50.tar' -C '/tmp/google-landmark/train'\n",
    "#!tar -tvf '/tmp/google-landmark/train/images_100.tar' -C '/tmp/google-landmark/train'\n",
    "#!tar -tvf '/tmp/google-landmark/train/images_150.tar' -C '/tmp/google-landmark/train'\n",
    "#!tar -tvf '/tmp/google-landmark/train/images_200.tar' -C '/tmp/google-landmark/train'\n",
    "#!tar -tvf '/tmp/google-landmark/train/images_250.tar' -C '/tmp/google-landmark/train'\n",
    "#!tar -tvf '/tmp/google-landmark/train/images_300.tar' -C '/tmp/google-landmark/train'\n",
    "#!tar -tvf '/tmp/google-landmark/train/images_350.tar' -C '/tmp/google-landmark/train'\n",
    "#!tar -xvf '/tmp/google-landmark/test/images_400.tar' -C '/tmp/google-landmark/test'\n",
    "\n",
    "\n",
    "import tarfile\n",
    "\n",
    "tar = tarfile.open(\"/tmp/google-landmark/test/images_000.tar\")\n",
    "tar.extractall('/tmp/google-landmark/train')\n",
    "tar.close()\n",
    "tar = tarfile.open(\"/tmp/google-landmark/train/images_050.tar\")\n",
    "tar.extractall('/tmp/google-landmark/train')\n",
    "tar.close()\n",
    "tar = tarfile.open(\"/tmp/google-landmark/train/images_100.tar\")\n",
    "tar.extractall('/tmp/google-landmark/train')\n",
    "tar.close()\n",
    "tar = tarfile.open(\"/tmp/google-landmark/train/images_150.tar\")\n",
    "tar.extractall('/tmp/google-landmark/train')\n",
    "tar.close()\n",
    "tar = tarfile.open(\"/tmp/google-landmark/train/images_200.tar\")\n",
    "tar.extractall('/tmp/google-landmark/train')\n",
    "tar.close()\n",
    "tar = tarfile.open(\"/tmp/google-landmark/train/images_250.tar\")\n",
    "tar.extractall('/tmp/google-landmark/train')\n",
    "tar.close()\n",
    "tar = tarfile.open(\"/tmp/google-landmark/train/images_300.tar\")\n",
    "tar.extractall('/tmp/google-landmark/train')\n",
    "tar.close()\n",
    "tar = tarfile.open(\"/tmp/google-landmark/train/images_350.tar\")\n",
    "tar.extractall('/tmp/google-landmark/train')\n",
    "tar.close()\n",
    "\n",
    "tar = tarfile.open(\"/tmp/google-landmark/test/images_400.tar\")\n",
    "tar.extractall('/tmp/google-landmark/test')\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-qUPyfO7Qr8"
   },
   "source": [
    "The contents of the .zip are extracted to the base directory `/tmp/google-landmark`, which in turn each contain `train` and `test` subdirectories.\n",
    "\n",
    "In short: The training set is the data that is used to tell the neural network model that 'this is what a horse looks like', 'this is what a human looks like' etc. \n",
    "\n",
    "One thing to pay attention to in this sample: We do not explicitly label the images as horses or humans. If you remember with the handwriting example earlier, we had labelled 'this is a 1', 'this is a 7' etc.  Later you'll see something called an ImageGenerator being used -- and this is coded to read images from subdirectories, and automatically label them from the name of that subdirectory. So, for example, you will have a 'training' directory containing a 'horses' directory and a 'humans' one. ImageGenerator will label the images appropriately for you, reducing a coding step. \n",
    "\n",
    "Let's define each of these directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NR_M9nWN-K8B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Directory with our training pictures\n",
    "train_dir = os.path.join('/tmp/google-landmark/train')\n",
    "\n",
    "# Directory with our validation pictures\n",
    "validation_dir = os.path.join('/tmp/google-landmark/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2xcTMKw3b-9g",
    "outputId": "0d5b96f8-8250-489a-c8b4-50f7b6c2f733"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203094"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create dataframes for ImageDataGenerators flow_from_dataframe\n",
    "\n",
    "train_df = pd.read_csv(r\"/tmp/google-landmark/train.csv\", dtype=str)\n",
    "validation_df = pd.read_csv(r\"/tmp/google-landmark/test.csv\", dtype=str)\n",
    "\n",
    "# Data cleaning, remove None url's\n",
    "train_df['id'] = train_df['id'].str.strip()\n",
    "train_df = train_df[train_df['url'] != \"None\"]\n",
    "train_df = train_df.drop(columns=['url'])\n",
    "validation_df['id'] = validation_df['id'].str.strip()\n",
    "validation_df = validation_df[validation_df['url'] != \"None\"]\n",
    "validation_df = validation_df.drop(columns=['url'])\n",
    "\n",
    "# Obtain number of classes to create model's sotfmax layer later\n",
    "landmarks = train_df.groupby(\"landmark_id\").count()\n",
    "max_classes = landmarks.count()['id']\n",
    "max_classes\n",
    "#landmarks[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ScSnwSpbV4hC",
    "outputId": "1d0d6318-4a03-4dac-b5ef-42f717d3bac8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7444"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temporary restrict dataframes to loaded tar images\n",
    "# due to restriction of disk space in colab environment\n",
    "pretrain_df = train_df\n",
    "temp_df = pd.DataFrame(columns=['id'], dtype=str)\n",
    "for path,dir,file in os.walk('/tmp/google-landmark/train'):\n",
    "  for fn in file:\n",
    "    temp_df = temp_df.append({'id': fn[:-4]}, ignore_index=True)\n",
    "\n",
    "train_df = pretrain_df.loc[pretrain_df['id'].isin(temp_df['id'])]\n",
    "\n",
    "temp_df=pd.DataFrame(columns=['id'], dtype=str)\n",
    "for path,dir,file in os.walk('/tmp/google-landmark/test'):\n",
    "  for fn in file:  \n",
    "    temp_df = temp_df.append({'id': fn[:-4]}, ignore_index=True)\n",
    "\n",
    "validation_df = pretrain_df.loc[pretrain_df['id'].isin(temp_df['id'])]\n",
    "\n",
    "# Try to fix None of Index are in columns error\n",
    "#train_df.reset_index(drop=True)\n",
    "#validation_df.reset_index(drop=True)\n",
    "\n",
    "landmarks = train_df.groupby(\"landmark_id\").count()\n",
    "max_classes = landmarks.count()[\"id\"]\n",
    "max_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3070894</th>\n",
       "      <td>0/0/5/0052fab157ef0378.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678623</th>\n",
       "      <td>0/0/5/005f96df8c157368.jpg</td>\n",
       "      <td>100051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072798</th>\n",
       "      <td>0/0/3/00348255337f5a31.jpg</td>\n",
       "      <td>100089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169123</th>\n",
       "      <td>0/0/6/006a74e406f2aa87.jpg</td>\n",
       "      <td>100103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314403</th>\n",
       "      <td>0/0/6/0062527662f743e2.jpg</td>\n",
       "      <td>100125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id landmark_id\n",
       "3070894  0/0/5/0052fab157ef0378.jpg           0\n",
       "1678623  0/0/5/005f96df8c157368.jpg      100051\n",
       "4072798  0/0/3/00348255337f5a31.jpg      100089\n",
       "1169123  0/0/6/006a74e406f2aa87.jpg      100103\n",
       "2314403  0/0/6/0062527662f743e2.jpg      100125"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_values(['landmark_id'], ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5oqBkNBJmtUv"
   },
   "source": [
    "## Building a Small Model from Scratch\n",
    "\n",
    "But before we continue, let's start defining the model:\n",
    "\n",
    "Step 1 will be to import tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "qvfZg3LQbD-5",
    "outputId": "7a1933e8-804b-46e2-e3c3-aef64f544b10",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install --pre -U tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnhYCP4tdqjC"
   },
   "source": [
    "We then add convolutional layers as in the previous example, and flatten the final result to feed into the densely connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gokG5HKpdtzm"
   },
   "source": [
    "Finally we add the densely connected layers. \n",
    "\n",
    "Note that because we are facing a two-class classification problem, i.e. a *binary classification problem*, we will end our network with a [*softmax* activation](https://wikipedia.org/wiki/Sigmoid_function), so that the output of our network will be a single scalar between 0 and 1, encoding the probability that the current image is class 1 (as opposed to class 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PixZ2s5QbYQ3",
    "outputId": "c70ed65d-8e12-41c1-aa03-7104dc6b30d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will not apply HSTS. The HSTS database must be a regular and non-world-writable file.\n",
      "ERROR: could not open HSTS store at '/home/enri/.wget-hsts'. HSTS will be disabled.\n",
      "--2019-05-23 21:19:58--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.168.176, 2a00:1450:4003:80a::2010\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.168.176|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87910968 (84M) [application/x-hdf]\n",
      "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
      "\n",
      "/tmp/inception_v3_w 100%[===================>]  83.84M  5.81MB/s    in 14s     \n",
      "\n",
      "2019-05-23 21:20:13 (5.90 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
      "\n",
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "#!wget --no-check-certificate \\\n",
    "#    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "#    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False\n",
    "  \n",
    "# pre_trained_model.summary()\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# In case of use of InceptionV3 transfer learning\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output) # In case of use of InceptionV3 transfer learning\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final softmax layer for classification\n",
    "x = layers.Dense(max_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "# In case of use of C3-MP-DNN architecture\n",
    "# Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "#model = tf.keras.models.Sequential([\n",
    "#tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "#tf.keras.layers.MaxPooling2D(2,2),\n",
    "#tf.keras.layers.Dropout(0.1),\n",
    "#tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "#tf.keras.layers.MaxPooling2D(2,2),\n",
    "#tf.keras.layers.Dropout(0.2),\n",
    "#tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
    "#tf.keras.layers.MaxPooling2D(2,2),\n",
    "#tf.keras.layers.Dropout(0.3),\n",
    "# Flatten the output layer to 1 dimension\n",
    "#tf.keras.layers.Flatten(),\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "#tf.keras.layers.Dense(512, activation='relu'),\n",
    "# Add a dropout rate of 0.2\n",
    "#tf.keras.layers.Dropout(0.2),                 \n",
    "# Add a final softmax layer for classification\n",
    "#tf.keras.layers.Dense  (max_classes, activation='softmax')\n",
    "#])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9EaFDP5srBa"
   },
   "source": [
    "model = Model( pre_trained_model.input, x) The model.summary() method call prints a summary of the NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9054
    },
    "colab_type": "code",
    "id": "7ZKj8392nbgP",
    "outputId": "20b0d9dd-0488-4954-986f-15d95686fab5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_94 (Batc (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_v1_94[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_95 (Batc (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_v1_95[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_96 (Batc (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_v1_96[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_97 (Batc (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_v1_97[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_98 (Batc (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_v1_98[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_102 (Bat (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_102[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_100 (Bat (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_103 (Bat (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_100[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_103[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_99 (Batc (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_101 (Bat (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_104 (Bat (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_105 (Bat (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_99[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_101[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_104[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_v1_105[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_109 (Bat (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_109[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_107 (Bat (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_110 (Bat (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_107[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_110[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_106 (Bat (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_108 (Bat (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_111 (Bat (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_112 (Bat (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_106[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_108[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_111[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_112[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_116 (Bat (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_116[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_114 (Bat (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_117 (Bat (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_114[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_117[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_113 (Bat (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_115 (Bat (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_118 (Bat (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_119 (Bat (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_113[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_115[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_118[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_119[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_121 (Bat (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_121[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_122 (Bat (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_122[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_120 (Bat (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_123 (Bat (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_v1_120[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_v1_123[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_128 (Bat (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_128[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_129 (Bat (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_129[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_125 (Bat (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_130 (Bat (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_125[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_130[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_126 (Bat (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_131 (Bat (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_126[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_131[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_124 (Bat (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_127 (Bat (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_132 (Bat (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_133 (Bat (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_124[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_127[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_132[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_133[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_138 (Bat (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_138[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_139 (Bat (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_139[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_135 (Bat (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_140 (Bat (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_135[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_140[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_136 (Bat (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_141 (Bat (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_136[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_141[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_134 (Bat (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_137 (Bat (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_142 (Bat (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_143 (Bat (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_134[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_137[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_142[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_143[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_148 (Bat (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_148[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_149 (Bat (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_149[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_145 (Bat (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_150 (Bat (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_145[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_150[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_146 (Bat (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_151 (Bat (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_146[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_151[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_144 (Bat (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_147 (Bat (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_152 (Bat (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_153 (Bat (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_144[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_147[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_152[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_153[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_158 (Bat (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_158[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_159 (Bat (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_159[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_155 (Bat (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_160 (Bat (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_155[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_160[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_156 (Bat (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_161 (Bat (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_156[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_161[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_154 (Bat (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_157 (Bat (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_162 (Bat (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_163 (Bat (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_154[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_157[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_162[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_163[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          19268096    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 7444)         3818772     dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 32,062,132\n",
      "Trainable params: 23,086,868\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model( pre_trained_model.input, x) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DmtkTn06pKxF"
   },
   "source": [
    "The \"output shape\" column shows how the size of your feature map evolves in each successive layer. The convolution layers reduce the size of the feature maps by a bit due to padding, and each pooling layer halves the dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PEkKSpZlvJXA"
   },
   "source": [
    "Next, we'll configure the specifications for model training. We will train our model with the `categorical_crossentropy` loss, because it's a multiple classes classification problem and our final activation is a sigmoid. (For a refresher on loss metrics, see the [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/descending-into-ml/video-lecture).) We will use the `rmsprop` optimizer with a learning rate of `0.001`. During training, we will want to monitor classification accuracy.\n",
    "\n",
    "**NOTE**: In this case, using the [RMSprop optimization algorithm](https://wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp) is preferable to [stochastic gradient descent](https://developers.google.com/machine-learning/glossary/#SGD) (SGD), because RMSprop automates learning-rate tuning for us. (Other optimizers, such as [Adam](https://wikipedia.org/wiki/Stochastic_gradient_descent#Adam) and [Adagrad](https://developers.google.com/machine-learning/glossary/#AdaGrad), also automatically adapt the learning rate during training, and would work equally well here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8DHWhFP_uhq3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sn9m9D3UimHM"
   },
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Let's set up data generators that will read pictures in our source folders, convert them to `float32` tensors, and feed them (with their labels) to our network. We'll have one generator for the training images and one for the validation images. Our generators will yield batches of images of size 300x300 and their labels (binary).\n",
    "\n",
    "As you may already know, data that goes into neural networks should usually be normalized in some way to make it more amenable to processing by the network. (It is uncommon to feed raw pixels into a convnet.) In our case, we will preprocess our images by normalizing the pixel values to be in the `[0, 1]` range (originally all values are in the `[0, 255]` range).\n",
    "\n",
    "In Keras this can be done via the `keras.preprocessing.image.ImageDataGenerator` class using the `rescale` parameter. This `ImageDataGenerator` class allows you to instantiate generators of augmented image batches (and their labels) via `.flow(data, labels)` or `.flow_from_directory(directory)`. These generators can then be used with the Keras model methods that accept data generators as inputs: `fit_generator`, `evaluate_generator`, and `predict_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "id": "x4Imls9zO3Qs",
    "outputId": "4f0008ae-9ac2-460b-ef6d-cb7d48b8e7ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0/0/3/0036d78c05c194d9.jpg</td>\n",
       "      <td>50089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>0/0/1/001cd787f1e9a803.jpg</td>\n",
       "      <td>61937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>0/0/4/00429b0a692bc6ec.jpg</td>\n",
       "      <td>183170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>0/0/8/0082fd4214b3c2c7.jpg</td>\n",
       "      <td>36407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>0/0/2/002b386016930458.jpg</td>\n",
       "      <td>119649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id landmark_id\n",
       "108   0/0/3/0036d78c05c194d9.jpg       50089\n",
       "1262  0/0/1/001cd787f1e9a803.jpg       61937\n",
       "1567  0/0/4/00429b0a692bc6ec.jpg      183170\n",
       "2222  0/0/8/0082fd4214b3c2c7.jpg       36407\n",
       "3219  0/0/2/002b386016930458.jpg      119649"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add jpg extension to id column values\n",
    "def rename_id(id):\n",
    "  return id[0] + \"/\" + id[1] + \"/\" + id[2] + \"/\" + id + \".jpg\";\n",
    "\n",
    "train_df['id'] = train_df['id'].apply(rename_id)\n",
    "validation_df['id'] = validation_df['id'].apply(rename_id)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ClebU9NJg99G",
    "outputId": "7ecb494e-a64d-4176-c6d8-eaa9dda3d5f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8266 images belonging to 7444 classes.\n",
      "Found 8266 images belonging to 7483 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   zoom_range = 0.2) # Remove zoom_range augmentation when training the whole dataset          \n",
    "                                   #validation_split = 0.2)                        \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=train_dir, # This is the source directory for training images\n",
    "        x_col=\"id\",\n",
    "        y_col=\"landmark_id\",\n",
    "        shuffle=True,\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=512,\n",
    "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "        dataframe=validation_df,\n",
    "        directory=validation_dir,  # This is the source directory for training images\n",
    "        x_col=\"id\",\n",
    "        y_col=\"landmark_id\",\n",
    "        shuffle=True,\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=512,\n",
    "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mu3Jdwkjwax4"
   },
   "source": [
    "### Training\n",
    "Let's train for at least 50 epochs -- this may take quite a lot time to run...\n",
    "\n",
    "Do note the values per epoch.\n",
    "\n",
    "The Loss and Accuracy are a great indication of progress of training. It's making a guess as to the classification of the training data, and then measuring it against the known label, calculating the result. Accuracy is the portion of correct guesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Fb1_lgobv81m",
    "outputId": "24512efe-b996-4a47-d331-041434067492",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "15/16 [===========================>..] - ETA: 1:14 - loss: 0.0211 - acc: 0.9983"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (128, 7483) was passed for an output of shape (None, 7444) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-a1bf1f295081>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       validation_steps=STEP_SIZE_VALID)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m           \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[0;31m# Validate and standardize user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m     x, y, sample_weights = self._standardize_user_data(\n\u001b[0;32m-> 1312\u001b[0;31m         x, y, sample_weight=sample_weight, extract_tensors_from_dataset=True)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2655\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2657\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    510\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[1;32m    511\u001b[0m                            \u001b[0;34m' was passed for an output of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                            \u001b[0;34m' while using as loss `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m                            \u001b[0;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                            'as the output.')\n",
      "\u001b[0;31mValueError\u001b[0m: A target array with shape (128, 7483) was passed for an output of shape (None, 7444) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=STEP_SIZE_TRAIN,  \n",
    "      epochs=25,\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps=STEP_SIZE_VALID)\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h9iUfuU6UPxW"
   },
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    '/tmp/google-landmark/GLRC2019-earroyoh.hd5',\n",
    "    overwrite=False,\n",
    "    include_optimizer=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5WF5y2l4hknb"
   },
   "source": [
    "### Plot accuracy\n",
    "\n",
    "Plot training and validation accuracy to check overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "Q1dQ3LUvhViK",
    "outputId": "c22650f7-b1e9-4321-919b-af3d83e68357"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "#val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "#val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "#plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6vSHzPR2ghH"
   },
   "source": [
    "###Running the Model\n",
    "\n",
    "Let's now take a look at actually running a prediction using the model. This code will allow you to choose 1 or more files from your file system, it will then upload them, and run them through the model, giving an indication of whether the object is a horse or a human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "id": "DoWp43WxJDNT",
    "outputId": "c4565e7f-1ebe-45b3-db41-578f7aca0e65",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_max: 998\n",
      "prob: 1.0\n",
      "122600\n",
      "\n",
      "index_max: 4556\n",
      "prob: 0.64514136\n",
      "200348\n",
      "\n",
      "index_max: 6995\n",
      "prob: 1.0\n",
      "71123\n",
      "\n",
      "index_max: 998\n",
      "prob: 1.0\n",
      "122600\n",
      "\n",
      "index_max: 998\n",
      "prob: 1.0\n",
      "122600\n",
      "\n",
      "index_max: 6995\n",
      "prob: 1.0\n",
      "71123\n",
      "\n",
      "index_max: 998\n",
      "prob: 1.0\n",
      "122600\n",
      "\n",
      "index_max: 998\n",
      "prob: 0.9999896\n",
      "122600\n",
      "\n",
      "index_max: 998\n",
      "prob: 1.0\n",
      "122600\n",
      "\n",
      "index_max: 998\n",
      "prob: 0.8709269\n",
      "122600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from google.colab import files\n",
    "#from tf.keras.preprocessing import image\n",
    "\n",
    "uploaded = os.listdir('/tmp/google-landmark/test/c/c/f')\n",
    "\n",
    "for fn in uploaded[0:10]:\n",
    " \n",
    "  # predicting images\n",
    "  path = '/tmp/google-landmark/test/c/c/f/' + fn\n",
    "  img = tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
    "  x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "  images = np.vstack([x])\n",
    "  classes = model.predict(images, batch_size=10)\n",
    "  #print(classes[0])\n",
    "  index_max = np.argmax(classes[0])\n",
    "  print(\"index_max: \" + str(index_max))\n",
    "  print(\"prob: \" + str(classes[0][index_max]))                          \n",
    "  landmark_id_submission = train_df.sort_values(['landmark_id'], ascending=True).iloc[index_max]['landmark_id']\n",
    "  print(landmark_id_submission)\n",
    "  print()\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-8EHQyWGDvWz"
   },
   "source": [
    "### Visualizing Intermediate Representations\n",
    "\n",
    "--------DRAFT from Humans vs Dogs ----------\n",
    "\n",
    "To get a feel for what kind of features our convnet has learned, one fun thing to do is to visualize how an input gets transformed as it goes through the convnet.\n",
    "\n",
    "Let's pick a random image from the training set, and then generate a figure where each row is the output of a layer, and each image in the row is a specific filter in that output feature map. Rerun this cell to generate intermediate representations for a variety of training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "-5tES8rXFjux",
    "outputId": "68f394bf-3918-44e1-a5a4-fb6bbc9676e0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-410a39ea43f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvisualization_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuccessive_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Let's prepare a random input image from the training set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhorse_img_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_horse_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_horse_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mhuman_img_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_human_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_human_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhorse_img_files\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhuman_img_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_horse_names' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# Let's define a new Model that will take an image as input, and will output\n",
    "# intermediate representations for all layers in the previous model after\n",
    "# the first.\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "#visualization_model = Model(img_input, successive_outputs)\n",
    "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
    "# Let's prepare a random input image from the training set.\n",
    "train_horses_names = os.listdir(train_horse_dir)\n",
    "train_human_names = os.listdir(train_human_dir)\n",
    "horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n",
    "human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n",
    "img_path = random.choice(horse_img_files + human_img_files)\n",
    "\n",
    "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
    "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
    "\n",
    "# Rescale by 1/255\n",
    "x /= 255\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "# Now let's display our representations\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "  if len(feature_map.shape) == 4:\n",
    "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = feature_map.shape[1]\n",
    "    # We will tile our images in this matrix\n",
    "    display_grid = np.zeros((size, size * n_features))\n",
    "    for i in range(n_features):\n",
    "      # Postprocess the feature to make it visually palatable\n",
    "      x = feature_map[0, :, :, i]\n",
    "      x -= x.mean()\n",
    "      x /= x.std()\n",
    "      x *= 64\n",
    "      x += 128\n",
    "      x = np.clip(x, 0, 255).astype('uint8')\n",
    "      # We'll tile each filter into this big horizontal grid\n",
    "      display_grid[:, i * size : (i + 1) * size] = x\n",
    "    # Display the grid\n",
    "    scale = 20. / n_features\n",
    "    plt.figure(figsize=(scale * n_features, scale))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tuqK2arJL0wo"
   },
   "source": [
    "As you can see we go from the raw pixels of the images to increasingly abstract and compact representations. The representations downstream start highlighting what the network pays attention to, and they show fewer and fewer features being \"activated\"; most are set to zero. This is called \"sparsity.\" Representation sparsity is a key feature of deep learning.\n",
    "\n",
    "\n",
    "These representations carry increasingly less information about the original pixels of the image, but increasingly refined information about the class of the image. You can think of a convnet (or a deep network in general) as an information distillation pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4IBgYCYooGD"
   },
   "source": [
    "## Clean Up\n",
    "\n",
    "Before running the next exercise, run the following cell to terminate the kernel and free memory resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "651IgjLyo-Jx"
   },
   "outputs": [],
   "source": [
    "import os, signal\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "google-landmark-v2.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
