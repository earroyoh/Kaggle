{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google-landmark-v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/earroyoh/Kaggle/blob/master/Google-Landmark-Recognition-Challenge-2019/google-landmark-v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RXZT2UsyIVe_",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from shutil import copyfile,rmtree\n",
        "\n",
        "os.mkdir('/tmp/google-landmark')\n",
        "os.mkdir('/tmp/google-landmark/train')\n",
        "\n",
        "#rmtree('/tmp/google-landmark/test')\n",
        "os.mkdir('/tmp/google-landmark/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GrO42T6Etjy",
        "colab_type": "code",
        "outputId": "b816411c-2871-43b0-90c6-7308c44869b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1637
        }
      },
      "source": [
        "# Download training images\n",
        "# I just download a few ones to create the model and not oversize colab environment\n",
        "!wget --no-check-certificate \\\n",
        "     https://s3.amazonaws.com/google-landmark/train/images_000.tar \\\n",
        "    -O /tmp/google-landmark/train/images_000.tar\n",
        "!wget --no-check-certificate \\\n",
        "     https://s3.amazonaws.com/google-landmark/train/images_050.tar \\\n",
        "    -O /tmp/google-landmark/train/images_050.tar\n",
        "!wget --no-check-certificate \\\n",
        "     https://s3.amazonaws.com/google-landmark/train/images_100.tar \\\n",
        "    -O /tmp/google-landmark/train/images_100.tar\n",
        "!wget --no-check-certificate \\\n",
        "     https://s3.amazonaws.com/google-landmark/train/images_150.tar \\\n",
        "    -O /tmp/google-landmark/train/images_150.tar\n",
        "!wget --no-check-certificate \\\n",
        "     https://s3.amazonaws.com/google-landmark/train/images_200.tar \\\n",
        "    -O /tmp/google-landmark/train/images_200.tar\n",
        "!wget --no-check-certificate \\\n",
        "     https://s3.amazonaws.com/google-landmark/train/images_250.tar \\\n",
        "    -O /tmp/google-landmark/train/images_250.tar\n",
        "!wget --no-check-certificate \\\n",
        "     https://s3.amazonaws.com/google-landmark/train/images_300.tar \\\n",
        "    -O /tmp/google-landmark/train/images_300.tar\n",
        "!wget --no-check-certificate \\\n",
        "     https://s3.amazonaws.com/google-landmark/train/images_350.tar \\\n",
        "    -O /tmp/google-landmark/train/images_350.tar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-21 15:56:47--  https://s3.amazonaws.com/google-landmark/train/images_000.tar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.186.117\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.186.117|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1067018752 (1018M) [application/x-tar]\n",
            "Saving to: ‘/tmp/google-landmark/train/images_000.tar’\n",
            "\n",
            "/tmp/google-landmar 100%[===================>]   1018M  39.3MB/s    in 28s     \n",
            "\n",
            "2019-05-21 15:57:15 (37.0 MB/s) - ‘/tmp/google-landmark/train/images_000.tar’ saved [1067018752/1067018752]\n",
            "\n",
            "--2019-05-21 15:57:15--  https://s3.amazonaws.com/google-landmark/train/images_050.tar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.135.29\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.135.29|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1066296320 (1017M) [application/x-tar]\n",
            "Saving to: ‘/tmp/google-landmark/train/images_050.tar’\n",
            "\n",
            "/tmp/google-landmar 100%[===================>]   1017M  59.6MB/s    in 20s     \n",
            "\n",
            "2019-05-21 15:57:35 (51.7 MB/s) - ‘/tmp/google-landmark/train/images_050.tar’ saved [1066296320/1066296320]\n",
            "\n",
            "--2019-05-21 15:57:36--  https://s3.amazonaws.com/google-landmark/train/images_100.tar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.179.149\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.179.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1073758208 (1.0G) [application/x-tar]\n",
            "Saving to: ‘/tmp/google-landmark/train/images_100.tar’\n",
            "\n",
            "/tmp/google-landmar 100%[===================>]   1.00G  58.3MB/s    in 18s     \n",
            "\n",
            "2019-05-21 15:57:54 (57.7 MB/s) - ‘/tmp/google-landmark/train/images_100.tar’ saved [1073758208/1073758208]\n",
            "\n",
            "--2019-05-21 15:57:55--  https://s3.amazonaws.com/google-landmark/train/images_150.tar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.147.45\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.147.45|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1070785536 (1021M) [application/x-tar]\n",
            "Saving to: ‘/tmp/google-landmark/train/images_150.tar’\n",
            "\n",
            "/tmp/google-landmar 100%[===================>]   1021M  52.2MB/s    in 19s     \n",
            "\n",
            "2019-05-21 15:58:15 (52.9 MB/s) - ‘/tmp/google-landmark/train/images_150.tar’ saved [1070785536/1070785536]\n",
            "\n",
            "--2019-05-21 15:58:16--  https://s3.amazonaws.com/google-landmark/train/images_200.tar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.145.237\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.145.237|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1073142784 (1023M) [application/x-tar]\n",
            "Saving to: ‘/tmp/google-landmark/train/images_200.tar’\n",
            "\n",
            "/tmp/google-landmar 100%[===================>]   1023M  59.9MB/s    in 18s     \n",
            "\n",
            "2019-05-21 15:58:35 (55.5 MB/s) - ‘/tmp/google-landmark/train/images_200.tar’ saved [1073142784/1073142784]\n",
            "\n",
            "--2019-05-21 15:58:35--  https://s3.amazonaws.com/google-landmark/train/images_250.tar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.0.198\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.0.198|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1070467072 (1021M) [application/x-tar]\n",
            "Saving to: ‘/tmp/google-landmark/train/images_250.tar’\n",
            "\n",
            "/tmp/google-landmar 100%[===================>]   1021M  51.6MB/s    in 19s     \n",
            "\n",
            "2019-05-21 15:58:55 (53.5 MB/s) - ‘/tmp/google-landmark/train/images_250.tar’ saved [1070467072/1070467072]\n",
            "\n",
            "--2019-05-21 15:58:56--  https://s3.amazonaws.com/google-landmark/train/images_300.tar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.137.254\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.137.254|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1072676864 (1023M) [application/x-tar]\n",
            "Saving to: ‘/tmp/google-landmark/train/images_300.tar’\n",
            "\n",
            "/tmp/google-landmar 100%[===================>]   1023M  52.0MB/s    in 20s     \n",
            "\n",
            "2019-05-21 15:59:16 (50.3 MB/s) - ‘/tmp/google-landmark/train/images_300.tar’ saved [1072676864/1072676864]\n",
            "\n",
            "--2019-05-21 15:59:18--  https://s3.amazonaws.com/google-landmark/train/images_350.tar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.10.93\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.10.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1073489920 (1024M) [application/x-tar]\n",
            "Saving to: ‘/tmp/google-landmark/train/images_350.tar’\n",
            "\n",
            "/tmp/google-landmar 100%[===================>]   1024M  59.9MB/s    in 20s     \n",
            "\n",
            "2019-05-21 15:59:38 (50.9 MB/s) - ‘/tmp/google-landmark/train/images_350.tar’ saved [1073489920/1073489920]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mLij6qde6Ox",
        "colab_type": "code",
        "outputId": "06bf7d22-0b55-47c8-bc29-56d68d3b46de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "# Download a training file as validation file\n",
        "!wget --no-check-certificate \\\n",
        "     https://s3.amazonaws.com/google-landmark/train/images_400.tar \\\n",
        "    -O /tmp/google-landmark/test/images_400.tar "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-21 15:59:47--  https://s3.amazonaws.com/google-landmark/train/images_400.tar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.139.45\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.139.45|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1073154048 (1023M) [application/x-tar]\n",
            "Saving to: ‘/tmp/google-landmark/test/images_400.tar’\n",
            "\n",
            "/tmp/google-landmar 100%[===================>]   1023M  59.1MB/s    in 18s     \n",
            "\n",
            "2019-05-21 16:00:05 (57.8 MB/s) - ‘/tmp/google-landmark/test/images_400.tar’ saved [1073154048/1073154048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9brUxyTpYZHy",
        "colab_type": "text"
      },
      "source": [
        "The following python code will use the OS library to use Operating System libraries, giving you access to the file system, and the zipfile library allowing you to unzip the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMhhz6dPKgWC",
        "colab_type": "code",
        "outputId": "ba096272-40a5-4470-a38c-ad4d9ebf3d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# Download CSV datasets with images id's and landmarks id's\n",
        "#!wget --no-check-certificate \\\n",
        "#     https://www.kaggle.com/google/google-landmarks-dataset/downloads/google-landmarks-dataset.zip \\\n",
        "#    -O /tmp/google-landmark/google-landmarks-dataset.zip\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "     https://s3.amazonaws.com/google-landmark/metadata/train.csv \\\n",
        "    -O /tmp/google-landmark/train.csv\n",
        "#!wget --no-check-certificate \\\n",
        "#     https://s3.amazonaws.com/google-landmark/metadata/test.csv \\\n",
        "#    -O /tmp/google-landmark/test.csv\n",
        "\n",
        "  \n",
        "# Extract files\n",
        "#import zipfile\n",
        "\n",
        "#local_zip = '/tmp/google-landmark/google-landmarks-dataset.zip'\n",
        "#zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "#zip_ref.extractall('/tmp/google-landmark')\n",
        "#zip_ref.close()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-21 16:00:09--  https://s3.amazonaws.com/google-landmark/metadata/train.csv\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.170.117\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.170.117|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 525832518 (501M) [text/csv]\n",
            "Saving to: ‘/tmp/google-landmark/train.csv’\n",
            "\n",
            "/tmp/google-landmar 100%[===================>] 501.47M  48.4MB/s    in 13s     \n",
            "\n",
            "2019-05-21 16:00:22 (39.4 MB/s) - ‘/tmp/google-landmark/train.csv’ saved [525832518/525832518]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PLy3pthUS0D2",
        "colab": {}
      },
      "source": [
        "# Extract images tar files\n",
        "\n",
        "# OS system calls\n",
        "#!tar -xvf '/tmp/google-landmark/train/images_000.tar' -C '/tmp/google-landmark/train'\n",
        "#!tar -tvf '/tmp/google-landmark/train/images_50.tar' -C '/tmp/google-landmark/train'\n",
        "#!tar -tvf '/tmp/google-landmark/train/images_100.tar' -C '/tmp/google-landmark/train'\n",
        "#!tar -tvf '/tmp/google-landmark/train/images_150.tar' -C '/tmp/google-landmark/train'\n",
        "#!tar -tvf '/tmp/google-landmark/train/images_200.tar' -C '/tmp/google-landmark/train'\n",
        "#!tar -tvf '/tmp/google-landmark/train/images_250.tar' -C '/tmp/google-landmark/train'\n",
        "#!tar -tvf '/tmp/google-landmark/train/images_300.tar' -C '/tmp/google-landmark/train'\n",
        "#!tar -tvf '/tmp/google-landmark/train/images_350.tar' -C '/tmp/google-landmark/train'\n",
        "#!tar -xvf '/tmp/google-landmark/test/images_400.tar' -C '/tmp/google-landmark/test'\n",
        "\n",
        "\n",
        "import tarfile\n",
        "\n",
        "tar = tarfile.open(\"/tmp/google-landmark/train/images_000.tar\")\n",
        "tar.extractall('/tmp/google-landmark/train')\n",
        "tar.close()\n",
        "tar = tarfile.open(\"/tmp/google-landmark/train/images_050.tar\")\n",
        "tar.extractall('/tmp/google-landmark/train')\n",
        "tar.close()\n",
        "tar = tarfile.open(\"/tmp/google-landmark/train/images_100.tar\")\n",
        "tar.extractall('/tmp/google-landmark/train')\n",
        "tar.close()\n",
        "tar = tarfile.open(\"/tmp/google-landmark/train/images_150.tar\")\n",
        "tar.extractall('/tmp/google-landmark/train')\n",
        "tar.close()\n",
        "tar = tarfile.open(\"/tmp/google-landmark/train/images_200.tar\")\n",
        "tar.extractall('/tmp/google-landmark/train')\n",
        "tar.close()\n",
        "tar = tarfile.open(\"/tmp/google-landmark/train/images_250.tar\")\n",
        "tar.extractall('/tmp/google-landmark/train')\n",
        "tar.close()\n",
        "tar = tarfile.open(\"/tmp/google-landmark/train/images_300.tar\")\n",
        "tar.extractall('/tmp/google-landmark/train')\n",
        "tar.close()\n",
        "tar = tarfile.open(\"/tmp/google-landmark/train/images_350.tar\")\n",
        "tar.extractall('/tmp/google-landmark/train')\n",
        "tar.close()\n",
        "\n",
        "tar = tarfile.open(\"/tmp/google-landmark/test/images_400.tar\")\n",
        "tar.extractall('/tmp/google-landmark/test')\n",
        "tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o-qUPyfO7Qr8"
      },
      "source": [
        "The contents of the .zip are extracted to the base directory `/tmp/google-landmark`, which in turn each contain `train` and `test` subdirectories.\n",
        "\n",
        "In short: The training set is the data that is used to tell the neural network model that 'this is what a horse looks like', 'this is what a human looks like' etc. \n",
        "\n",
        "One thing to pay attention to in this sample: We do not explicitly label the images as horses or humans. If you remember with the handwriting example earlier, we had labelled 'this is a 1', 'this is a 7' etc.  Later you'll see something called an ImageGenerator being used -- and this is coded to read images from subdirectories, and automatically label them from the name of that subdirectory. So, for example, you will have a 'training' directory containing a 'horses' directory and a 'humans' one. ImageGenerator will label the images appropriately for you, reducing a coding step. \n",
        "\n",
        "Let's define each of these directories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NR_M9nWN-K8B",
        "colab": {}
      },
      "source": [
        "# Directory with our training pictures\n",
        "train_dir = os.path.join('/tmp/google-landmark/train')\n",
        "\n",
        "# Directory with our validation pictures\n",
        "validation_dir = os.path.join('/tmp/google-landmark/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xcTMKw3b-9g",
        "colab_type": "code",
        "outputId": "a0e9b5df-67c1-4149-d983-e58db744b2db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create dataframes for ImageDataGenerators flow_from_dataframe\n",
        "\n",
        "train_df = pd.read_csv(r\"/tmp/google-landmark/train.csv\", dtype=str)\n",
        "validation_df = pd.read_csv(r\"/tmp/google-landmark/test.csv\", dtype=str)\n",
        "\n",
        "# Data cleaning, remove None url's\n",
        "train_df['id'] = train_df['id'].str.strip()\n",
        "train_df = train_df[train_df[\"url\"] != \"None\"]\n",
        "validation_df['id'] = validation_df['id'].str.strip()\n",
        "validation_df = validation_df[validation_df[\"url\"] != \"None\"]\n",
        "\n",
        "# Obtain number of classes to create model's sotfmax layer later\n",
        "landmarks = train_df.groupby(\"landmark_id\").count()\n",
        "max_classes = landmarks.count()[\"id\"]\n",
        "max_classes\n",
        "#landmarks[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "203094"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtatwrobqBUC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScSnwSpbV4hC",
        "colab_type": "code",
        "outputId": "961cade9-723b-4b31-ad7b-597eaa17d9be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Temporary restrict dataframe to loaded tar images\n",
        "pretrain_df = train_df\n",
        "temp_df = pd.DataFrame(columns=['id'], dtype=str)\n",
        "for path,dir,file in os.walk('/tmp/google-landmark/train'):\n",
        "  for fn in file:\n",
        "    temp_df = temp_df.append({'id': fn[:-4]}, ignore_index=True)\n",
        "\n",
        "train_df = pretrain_df.loc[pretrain_df['id'].isin(temp_df['id'])]\n",
        "\n",
        "temp_df=pd.DataFrame(columns=['id'], dtype=str)\n",
        "for path,dir,file in os.walk('/tmp/google-landmark/test'):\n",
        "  for fn in file:  \n",
        "    temp_df = temp_df.append({'id': fn[:-4]}, ignore_index=True)\n",
        "\n",
        "validation_df = pretrain_df.loc[pretrain_df['id'].isin(temp_df['id'])]\n",
        "\n",
        "# Try to fix None of Index are in columns error\n",
        "#train_df.reset_index(drop=True)\n",
        "#validation_df.reset_index(drop=True)\n",
        "\n",
        "landmarks = train_df.groupby(\"landmark_id\").count()\n",
        "max_classes = landmarks.count()[\"id\"]\n",
        "max_classes"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41838"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk3pE6xCdDcl",
        "colab_type": "code",
        "outputId": "be541039-8d55-4896-a20f-f149027f12ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>landmark_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>33aab955d639297d</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>188405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0036d78c05c194d9</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>50089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>4cf93eb52b4f282c</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>181602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>19ec45a81f8ea0f8</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>48979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>b355ccc8a7d851c5</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>91884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id  ... landmark_id\n",
              "78   33aab955d639297d  ...      188405\n",
              "108  0036d78c05c194d9  ...       50089\n",
              "142  4cf93eb52b4f282c  ...      181602\n",
              "245  19ec45a81f8ea0f8  ...       48979\n",
              "282  b355ccc8a7d851c5  ...       91884\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5oqBkNBJmtUv"
      },
      "source": [
        "## Building a Small Model from Scratch\n",
        "\n",
        "But before we continue, let's start defining the model:\n",
        "\n",
        "Step 1 will be to import tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvfZg3LQbD-5",
        "colab_type": "code",
        "outputId": "1438a191-bf9a-4208-cbab-3ca8364a3109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        }
      },
      "source": [
        "!pip install --pre -U tensorflow\n",
        "import tensorflow as tf"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (79.9MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9MB 43.8MB/s \n",
            "\u001b[?25hCollecting google-pasta>=0.1.2 (from tensorflow)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/68/a14620bfb042691f532dcde8576ff82ee82e4c003cdc0a3dbee5f289cee6/google_pasta-0.1.6-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 27.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 54.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.3)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.4)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 53.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (41.0.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow) (0.15.3)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow) (3.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Installing collected packages: google-pasta, tb-nightly, tf-estimator-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed google-pasta-0.1.6 tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BnhYCP4tdqjC"
      },
      "source": [
        "We then add convolutional layers as in the previous example, and flatten the final result to feed into the densely connected layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gokG5HKpdtzm",
        "colab_type": "text"
      },
      "source": [
        "Finally we add the densely connected layers. \n",
        "\n",
        "Note that because we are facing a two-class classification problem, i.e. a *binary classification problem*, we will end our network with a [*softmax* activation](https://wikipedia.org/wiki/Sigmoid_function), so that the output of our network will be a single scalar between 0 and 1, encoding the probability that the current image is class 1 (as opposed to class 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PixZ2s5QbYQ3",
        "colab_type": "code",
        "outputId": "5bc3e932-1395-4ae7-d8d0-125fc1230bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# In case of use of InceptionV3 transfer learning\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output) # In case of use of InceptionV3 transfer learning\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final softmax layer for classification\n",
        "x = layers.Dense  (max_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "# Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "#model = tf.keras.models.Sequential([\n",
        "#tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "#tf.keras.layers.MaxPooling2D(2,2),\n",
        "#tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "#tf.keras.layers.MaxPooling2D(2,2), \n",
        "#tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "#tf.keras.layers.MaxPooling2D(2,2),\n",
        "# Flatten the output layer to 1 dimension\n",
        "#tf.keras.layers.Flatten(),\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "#tf.keras.layers.Dense(512, activation='relu'),\n",
        "# Add a dropout rate of 0.2\n",
        "#tf.keras.layers.Dropout(0.2),                 \n",
        "# Add a final softmax layer for classification\n",
        "#tf.keras.layers.Dense  (max_classes, activation='softmax')\n",
        "#])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-21 16:43:49--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.112.128, 2607:f8b0:4001:c05::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.112.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep  37%[======>             ]  31.66M   158MB/s               \r        /tmp/incept  85%[================>   ]  72.01M   167MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M   178MB/s    in 0.5s    \n",
            "\n",
            "2019-05-21 16:43:50 (178 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s9EaFDP5srBa"
      },
      "source": [
        "model = Model( pre_trained_model.input, x) The model.summary() method call prints a summary of the NN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7ZKj8392nbgP",
        "outputId": "20b0d9dd-0488-4954-986f-15d95686fab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9054
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_188 (Bat (None, 74, 74, 32)   96          conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_v1_188[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_189 (Bat (None, 72, 72, 32)   96          conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_v1_189[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_190 (Bat (None, 72, 72, 64)   192         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_v1_190[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 35, 35, 64)   0           activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_191 (Bat (None, 35, 35, 80)   240         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_v1_191[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_192 (Bat (None, 33, 33, 192)  576         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_v1_192[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 16, 16, 192)  0           activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_196 (Bat (None, 16, 16, 64)   192         conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_196[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_194 (Bat (None, 16, 16, 48)   144         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_197 (Bat (None, 16, 16, 96)   288         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_194[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_197[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_193 (Bat (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_195 (Bat (None, 16, 16, 64)   192         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_198 (Bat (None, 16, 16, 96)   288         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_199 (Bat (None, 16, 16, 32)   96          conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_193[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_195[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_198[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_v1_199[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
            "                                                                 activation_195[0][0]             \n",
            "                                                                 activation_198[0][0]             \n",
            "                                                                 activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_203 (Bat (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_203[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_201 (Bat (None, 16, 16, 48)   144         conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_204 (Bat (None, 16, 16, 96)   288         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_201[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_204[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_200 (Bat (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_202 (Bat (None, 16, 16, 64)   192         conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_205 (Bat (None, 16, 16, 96)   288         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_206 (Bat (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_200[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_202[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_205[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_206[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
            "                                                                 activation_202[0][0]             \n",
            "                                                                 activation_205[0][0]             \n",
            "                                                                 activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_210 (Bat (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_210[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_208 (Bat (None, 16, 16, 48)   144         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_211 (Bat (None, 16, 16, 96)   288         conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_208[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_211[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_207 (Bat (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_209 (Bat (None, 16, 16, 64)   192         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_212 (Bat (None, 16, 16, 96)   288         conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_213 (Bat (None, 16, 16, 64)   192         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_207[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_209[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_212[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_213[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
            "                                                                 activation_209[0][0]             \n",
            "                                                                 activation_212[0][0]             \n",
            "                                                                 activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_215 (Bat (None, 16, 16, 64)   192         conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_215[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_216 (Bat (None, 16, 16, 96)   288         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_216[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_214 (Bat (None, 7, 7, 384)    1152        conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_217 (Bat (None, 7, 7, 96)     288         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_v1_214[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_v1_217[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
            "                                                                 activation_217[0][0]             \n",
            "                                                                 max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_222 (Bat (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_222[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_223 (Bat (None, 7, 7, 128)    384         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_223[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_219 (Bat (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_224 (Bat (None, 7, 7, 128)    384         conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_219[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_224[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_220 (Bat (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_225 (Bat (None, 7, 7, 128)    384         conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_220[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_225[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_218 (Bat (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_221 (Bat (None, 7, 7, 192)    576         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_226 (Bat (None, 7, 7, 192)    576         conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_227 (Bat (None, 7, 7, 192)    576         conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_218[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_221[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_226[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_227[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
            "                                                                 activation_221[0][0]             \n",
            "                                                                 activation_226[0][0]             \n",
            "                                                                 activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_232 (Bat (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_232[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_233 (Bat (None, 7, 7, 160)    480         conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_233[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_229 (Bat (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_234 (Bat (None, 7, 7, 160)    480         conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_229[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_234[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_230 (Bat (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_235 (Bat (None, 7, 7, 160)    480         conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_230[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_235[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_228 (Bat (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_231 (Bat (None, 7, 7, 192)    576         conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_236 (Bat (None, 7, 7, 192)    576         conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_237 (Bat (None, 7, 7, 192)    576         conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_228[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_231[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_236[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_237[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
            "                                                                 activation_231[0][0]             \n",
            "                                                                 activation_236[0][0]             \n",
            "                                                                 activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_242 (Bat (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_242[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_243 (Bat (None, 7, 7, 160)    480         conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_243[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_239 (Bat (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_244 (Bat (None, 7, 7, 160)    480         conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_239[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_244[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_240 (Bat (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_245 (Bat (None, 7, 7, 160)    480         conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_240[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_245[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_238 (Bat (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_241 (Bat (None, 7, 7, 192)    576         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_246 (Bat (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_247 (Bat (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_238[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_241[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_246[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_247[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
            "                                                                 activation_241[0][0]             \n",
            "                                                                 activation_246[0][0]             \n",
            "                                                                 activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_252 (Bat (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_252[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_253 (Bat (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_253[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_249 (Bat (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_254 (Bat (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_249[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_254[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_250 (Bat (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_255 (Bat (None, 7, 7, 192)    576         conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_250[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_255[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_248 (Bat (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_251 (Bat (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_256 (Bat (None, 7, 7, 192)    576         conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_257 (Bat (None, 7, 7, 192)    576         conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_248[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_251[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_256[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_257[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
            "                                                                 activation_251[0][0]             \n",
            "                                                                 activation_256[0][0]             \n",
            "                                                                 activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 512)          19268096    flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 41838)        21462894    dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 49,706,254\n",
            "Trainable params: 40,730,990\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DmtkTn06pKxF"
      },
      "source": [
        "The \"output shape\" column shows how the size of your feature map evolves in each successive layer. The convolution layers reduce the size of the feature maps by a bit due to padding, and each pooling layer halves the dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PEkKSpZlvJXA"
      },
      "source": [
        "Next, we'll configure the specifications for model training. We will train our model with the `binary_crossentropy` loss, because it's a binary classification problem and our final activation is a sigmoid. (For a refresher on loss metrics, see the [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/descending-into-ml/video-lecture).) We will use the `rmsprop` optimizer with a learning rate of `0.001`. During training, we will want to monitor classification accuracy.\n",
        "\n",
        "**NOTE**: In this case, using the [RMSprop optimization algorithm](https://wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp) is preferable to [stochastic gradient descent](https://developers.google.com/machine-learning/glossary/#SGD) (SGD), because RMSprop automates learning-rate tuning for us. (Other optimizers, such as [Adam](https://wikipedia.org/wiki/Stochastic_gradient_descent#Adam) and [Adagrad](https://developers.google.com/machine-learning/glossary/#AdaGrad), also automatically adapt the learning rate during training, and would work equally well here.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8DHWhFP_uhq3",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sn9m9D3UimHM"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "Let's set up data generators that will read pictures in our source folders, convert them to `float32` tensors, and feed them (with their labels) to our network. We'll have one generator for the training images and one for the validation images. Our generators will yield batches of images of size 300x300 and their labels (binary).\n",
        "\n",
        "As you may already know, data that goes into neural networks should usually be normalized in some way to make it more amenable to processing by the network. (It is uncommon to feed raw pixels into a convnet.) In our case, we will preprocess our images by normalizing the pixel values to be in the `[0, 1]` range (originally all values are in the `[0, 255]` range).\n",
        "\n",
        "In Keras this can be done via the `keras.preprocessing.image.ImageDataGenerator` class using the `rescale` parameter. This `ImageDataGenerator` class allows you to instantiate generators of augmented image batches (and their labels) via `.flow(data, labels)` or `.flow_from_directory(directory)`. These generators can then be used with the Keras model methods that accept data generators as inputs: `fit_generator`, `evaluate_generator`, and `predict_generator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4Imls9zO3Qs",
        "colab_type": "code",
        "outputId": "f7cf9976-2fab-4e92-b2ca-b1026cf7fd0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "#Add jpg extension to id column values\n",
        "def rename_id(id):\n",
        "  return id[0] + \"/\" + id[1] + \"/\" + id[2] + \"/\" + id + \".jpg\";\n",
        "\n",
        "train_df['id'] = train_df['id'].apply(rename_id)\n",
        "validation_df['id'] = validation_df['id'].apply(rename_id)\n",
        "train_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>landmark_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>3/3/a/33aab955d639297d.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>188405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0/0/3/0036d78c05c194d9.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>50089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>4/c/f/4cf93eb52b4f282c.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>181602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>1/9/e/19ec45a81f8ea0f8.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>48979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>b/3/5/b355ccc8a7d851c5.jpg</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>91884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             id  ... landmark_id\n",
              "78   3/3/a/33aab955d639297d.jpg  ...      188405\n",
              "108  0/0/3/0036d78c05c194d9.jpg  ...       50089\n",
              "142  4/c/f/4cf93eb52b4f282c.jpg  ...      181602\n",
              "245  1/9/e/19ec45a81f8ea0f8.jpg  ...       48979\n",
              "282  b/3/5/b355ccc8a7d851c5.jpg  ...       91884\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ClebU9NJg99G",
        "outputId": "b7cb4913-b99a-4273-c7fc-99f258953096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   zoom_range = 0.2)\n",
        "                                   #validation_split = 0.2) # Remove zoom_range augmentation when training the whole dataset                                 \n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        directory=train_dir, # This is the source directory for training images\n",
        "        x_col=\"id\",\n",
        "        y_col=\"landmark_id\",\n",
        "        shuffle=True,\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=128,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "        dataframe=validation_df,\n",
        "        directory=validation_dir,  # This is the source directory for training images\n",
        "        x_col=\"id\",\n",
        "        y_col=\"landmark_id\",\n",
        "        shuffle=True,\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=32,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 66128 images belonging to 41838 classes.\n",
            "Found 8266 images belonging to 7483 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mu3Jdwkjwax4"
      },
      "source": [
        "### Training\n",
        "Let's train for 15 epochs -- this may take a few minutes to run.\n",
        "\n",
        "Do note the values per epoch.\n",
        "\n",
        "The Loss and Accuracy are a great indication of progress of training. It's making a guess as to the classification of the training data, and then measuring it against the known label, calculating the result. Accuracy is the portion of correct guesses. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fb1_lgobv81m",
        "outputId": "3f3960cb-8dc0-490c-93f0-c7637c184ed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=8,  \n",
        "      epochs=50,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      #validation_steps=8)\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "7/8 [=========================>....] - ETA: 8s - loss: 10.5816 - acc: 0.0022 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-9fbb5fc8fb63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0;31m#validation_steps=8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m           \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[0;31m# Validate and standardize user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m     x, y, sample_weights = self._standardize_user_data(\n\u001b[0;32m-> 1312\u001b[0;31m         x, y, sample_weight=sample_weight, extract_tensors_from_dataset=True)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2655\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2657\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    510\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[1;32m    511\u001b[0m                            \u001b[0;34m' was passed for an output of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                            \u001b[0;34m' while using as loss `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m                            \u001b[0;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                            'as the output.')\n",
            "\u001b[0;31mValueError\u001b[0m: A target array with shape (32, 7483) was passed for an output of shape (None, 41838) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9iUfuU6UPxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WF5y2l4hknb",
        "colab_type": "text"
      },
      "source": [
        "### Plot accuracy\n",
        "\n",
        "Plot training and validation accuracy to check overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1dQ3LUvhViK",
        "colab_type": "code",
        "outputId": "c22650f7-b1e9-4321-919b-af3d83e68357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-8bc21a7567ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6vSHzPR2ghH",
        "colab_type": "text"
      },
      "source": [
        "###Running the Model\n",
        "\n",
        "Let's now take a look at actually running a prediction using the model. This code will allow you to choose 1 or more files from your file system, it will then upload them, and run them through the model, giving an indication of whether the object is a horse or a human."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoWp43WxJDNT",
        "colab_type": "code",
        "outputId": "c4565e7f-1ebe-45b3-db41-578f7aca0e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a human\")\n",
        "  else:\n",
        "    print(fn + \" is a horse\")\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7214dc18-ad44-414e-9b40-250dca511d32\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7214dc18-ad44-414e-9b40-250dca511d32\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-83f6644adb6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: google.colab._files is undefined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-8EHQyWGDvWz"
      },
      "source": [
        "### Visualizing Intermediate Representations\n",
        "\n",
        "To get a feel for what kind of features our convnet has learned, one fun thing to do is to visualize how an input gets transformed as it goes through the convnet.\n",
        "\n",
        "Let's pick a random image from the training set, and then generate a figure where each row is the output of a layer, and each image in the row is a specific filter in that output feature map. Rerun this cell to generate intermediate representations for a variety of training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-5tES8rXFjux",
        "outputId": "68f394bf-3918-44e1-a5a4-fb6bbc9676e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Let's define a new Model that will take an image as input, and will output\n",
        "# intermediate representations for all layers in the previous model after\n",
        "# the first.\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "#visualization_model = Model(img_input, successive_outputs)\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
        "# Let's prepare a random input image from the training set.\n",
        "train_horse_names = os.listdir(train_horse_dir)\n",
        "train_human_names = os.listdir(train_human_dir)\n",
        "horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n",
        "human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n",
        "img_path = random.choice(horse_img_files + human_img_files)\n",
        "\n",
        "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
        "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
        "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /= 255\n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "# Now let's display our representations\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  if len(feature_map.shape) == 4:\n",
        "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = feature_map.shape[1]\n",
        "    # We will tile our images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    for i in range(n_features):\n",
        "      # Postprocess the feature to make it visually palatable\n",
        "      x = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std()\n",
        "      x *= 64\n",
        "      x += 128\n",
        "      x = np.clip(x, 0, 255).astype('uint8')\n",
        "      # We'll tile each filter into this big horizontal grid\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "    # Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure(figsize=(scale * n_features, scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-410a39ea43f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvisualization_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuccessive_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Let's prepare a random input image from the training set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhorse_img_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_horse_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_horse_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mhuman_img_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_human_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_human_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhorse_img_files\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhuman_img_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_horse_names' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tuqK2arJL0wo"
      },
      "source": [
        "As you can see we go from the raw pixels of the images to increasingly abstract and compact representations. The representations downstream start highlighting what the network pays attention to, and they show fewer and fewer features being \"activated\"; most are set to zero. This is called \"sparsity.\" Representation sparsity is a key feature of deep learning.\n",
        "\n",
        "\n",
        "These representations carry increasingly less information about the original pixels of the image, but increasingly refined information about the class of the image. You can think of a convnet (or a deep network in general) as an information distillation pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j4IBgYCYooGD"
      },
      "source": [
        "## Clean Up\n",
        "\n",
        "Before running the next exercise, run the following cell to terminate the kernel and free memory resources:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "651IgjLyo-Jx",
        "colab": {}
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}